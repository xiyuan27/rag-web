ä¸‹é¢æ˜¯æ–‡æ¡£çš„ç›®å½•ï¼Œè¯·å…ˆé¿å…é˜…è¯»å…¨æ–‡ã€‚æœç´¢æ–‡æ¡£å¼€å§‹åˆ°[ä»¥ä¸‹ä¸ºæ­£æ–‡]æˆªè‡³ï¼Œè·å–åˆ°ç›®å½•ï¼Œç„¶åæ ¹æ®ç›®å½•çš„ç« èŠ‚æ ‡é¢˜å†…å®¹æœç´¢ä½ æ„Ÿå…´è¶£çš„ç« èŠ‚ã€‚æ¯”å¦‚grepä¸¤ä¸ªç« èŠ‚æ ‡é¢˜ä¹‹é—´çš„éƒ¨åˆ†

------

# ğŸ“‘ ç›®å½•

## 1. é¡¹ç›®æ¦‚è¿°

## 2. æŠ€æœ¯æ ˆå’Œæ ¸å¿ƒæ¡†æ¶

- 2.1 Webæ¡†æ¶
- 2.2 æ•°æ®åº“å’ŒORM
- 2.3 å¼‚æ­¥å¤„ç†å’Œå¹¶å‘
- 2.4 å­˜å‚¨å’Œç¼“å­˜
- 2.5 AIå’Œæœºå™¨å­¦ä¹ 

## 3. é¡¹ç›®ç›®å½•ç»“æ„åˆ†æ

- 3.1 æ ¸å¿ƒç›®å½•ç»“æ„
- 3.2 å¯åŠ¨è„šæœ¬åˆ†æ

## 4. Flaskåº”ç”¨æ¶æ„

- 4.1 åº”ç”¨åˆå§‹åŒ–
- 4.2 ä¸»è¦è·¯ç”±æ¨¡å—
- 4.3 è®¤è¯æœºåˆ¶

## 5. æ•°æ®åº“æ¶æ„

- 5.1 æ•°æ®æ¨¡å‹è®¾è®¡
- 5.2 æœåŠ¡å±‚æ¶æ„

## 6. RAGæ ¸å¿ƒæ¨¡å—

- 6.1 æ–‡æ¡£è§£æå™¨
- 6.2 å¤§è¯­è¨€æ¨¡å‹å°è£…
- 6.3 è‡ªç„¶è¯­è¨€å¤„ç†
- 6.4 åå°æœåŠ¡

## 7. å¯¹è¯ç³»ç»Ÿæ ¸å¿ƒæµç¨‹

- 7.1 å¯¹è¯å¤„ç†æµç¨‹
- 7.2 æ£€ç´¢å¢å¼ºæœºåˆ¶

## 8. æ’ä»¶ç³»ç»Ÿ

- 8.1 æ’ä»¶æ¡†æ¶
- 8.2 æ™ºèƒ½ä½“ç³»ç»Ÿ

## 9. é…ç½®å’Œéƒ¨ç½²

- 9.1 é…ç½®æ–‡ä»¶è¯´æ˜
- 9.2 ä¾èµ–ç®¡ç†
- 9.3 å¯åŠ¨å‘½ä»¤

## 10. å…³é”®ç‰¹æ€§

- 10.1 å¤šç§Ÿæˆ·æ¶æ„
- 10.2 é«˜å¹¶å‘å¤„ç†
- 10.3 å¯æ‰©å±•æ€§
- 10.4 ä¼ä¸šçº§ç‰¹æ€§

## 11. æ€§èƒ½ä¼˜åŒ–

- 11.1 ç¼“å­˜ç­–ç•¥
- 11.2 èµ„æºç®¡ç†

## 12. å‰ç«¯APIæ¥å£æ¸…å•

- 12.1 ç”¨æˆ·ç®¡ç†æ¥å£
- 12.2 çŸ¥è¯†åº“ç®¡ç†æ¥å£
- 12.3 æ–‡æ¡£ç®¡ç†æ¥å£
- 12.4 å¯¹è¯åº”ç”¨æ¥å£
- 12.5 ä¼šè¯ç®¡ç†æ¥å£
- 12.6 å¤–éƒ¨APIæ¥å£
- 12.7 æ™ºèƒ½ä½“æ¥å£
- 12.8 æ¨¡å‹ç®¡ç†æ¥å£
- 12.9 æ–‡æ¡£å—ç®¡ç†æ¥å£
- 12.10 æ–‡ä»¶ç®¡ç†æ¥å£

## 13. æ•°æ®åº“è¡¨ç»“æ„è®¾è®¡

- 13.1 æ•°æ®åº“è¡¨ç»“æ„æ¦‚è§ˆ
- 13.2 æ ¸å¿ƒè¡¨ç»“æ„å…³ç³»
- 13.3 å…³é”®ä¸šåŠ¡è¡¨è¯´æ˜

## 14. çŸ¥è¯†åº“æ•°æ®é›†ç®¡ç†æµç¨‹

- 14.1 çŸ¥è¯†åº“åˆ›å»ºæµç¨‹
- 14.2 æ–‡æ¡£ä¸Šä¼ æµç¨‹
- 14.3 æ–‡æ¡£è§£æå’Œåˆ†å—æµç¨‹
- 14.4 æ–‡æ¡£åˆ é™¤æµç¨‹è¯¦è§£
- 14.5 çŸ¥è¯†åº“åˆ é™¤æµç¨‹
- 14.6 é”™è¯¯å¤„ç†å’Œå›æ»šæœºåˆ¶

## 15. æ–‡ä»¶å­˜å‚¨æ¶æ„

- 15.1 å­˜å‚¨ç³»ç»Ÿæ¦‚è¿°
- 15.2 å­˜å‚¨ç±»å‹æ”¯æŒ
- 15.3 é…ç½®å’Œåˆå§‹åŒ–
- 15.4 MinIOå­˜å‚¨å®ç°åˆ†æ
- 15.5 æœ¬åœ°å­˜å‚¨å®ç°åˆ†æ
- 15.6 æœ¬åœ°å­˜å‚¨æ½œåœ¨Bugåˆ†æ
- 15.7 å­˜å‚¨ä½¿ç”¨åœºæ™¯
- 15.8 å­˜å‚¨è·¯å¾„ä¿å­˜æœºåˆ¶
- 15.9 æ–‡ä»¶é‡å‘½åæœºåˆ¶è¯¦è§£
- 15.10 å­˜å‚¨ç›‘æ§å’Œç»´æŠ¤
- 15.11 æœ€ä½³å®è·µå»ºè®®

## 16. å¼‚å¸¸å¤„ç†æœºåˆ¶

- 16.1 å¼‚å¸¸å¤„ç†æ¶æ„æ¦‚è¿°
- 16.2 å¼‚å¸¸åˆ†ç±»å’Œé”™è¯¯ç ä½“ç³»
- 16.3 å¼‚å¸¸å¤„ç†æµç¨‹
- 16.4 å‰ç«¯å¼‚å¸¸ä¿¡æ¯å¤„ç†
- 16.5 å¼‚å¸¸ç›‘æ§å’Œå‘Šè­¦
- 16.6 å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ

## 17. æ—¥å¿—å¤„ç†æœºåˆ¶

- 17.1 æ—¥å¿—ç³»ç»Ÿæ¶æ„
- 17.2 æ—¥å¿—çº§åˆ«é…ç½®
- 17.3 æ—¥å¿—è®°å½•æ¨¡å¼
- 17.4 æ—¥å¿—åˆ†æ–‡ä»¶æ–¹æ¡ˆè®¾è®¡
- 17.5 å¼‚å¸¸æ—¥å¿—å¢å¼ºæ ¼å¼
- 17.6 å‰ç«¯å‹å¥½çš„é”™è¯¯å¤„ç†
- 17.7 æ—¥å¿—ç›‘æ§å’Œåˆ†æ
- 17.8 æ—¥å¿—é…ç½®å»ºè®®

## 18. æ•°æ®åº“åˆå§‹åŒ–æœºåˆ¶

- 18.1 è‡ªåŠ¨åˆå§‹åŒ–æ¦‚è¿°
- 18.2 æ ¸å¿ƒåˆå§‹åŒ–å‡½æ•°
- 18.3 æ•°æ®åº“è¿ç§»æœºåˆ¶
- 18.4 æ•°æ®æ¨¡å‹åŸºç±»
- 18.5 ç³»ç»Ÿå¯åŠ¨åºåˆ—
- 18.6 é”™è¯¯å¤„ç†ä¸æ¢å¤æœºåˆ¶
- 18.7 æ”¯æŒçš„æ•°æ®åº“ç±»å‹
- 18.8 é…ç½®è¦æ±‚å’Œæœ€ä½³å®è·µ
- 18.9 æ‰©å±•ä¸å®šåˆ¶

## 19. æ–‡æ¡£åˆ‡ç‰‡æ–¹æ³•ä¸“é¢˜çŸ¥è¯†

- 19.1 åˆ‡ç‰‡ç³»ç»Ÿæ¶æ„æ¦‚è¿°
- 19.2 ç°æœ‰åˆ‡ç‰‡æ–¹æ³•è¯¦è§£
- 19.3 RAPTORä¸TAGå¢å¼ºæœºåˆ¶
- 19.4 å‰ç«¯é…ç½®ç³»ç»Ÿ
- 19.5 å—ç®¡ç†APIç³»ç»Ÿ
- 19.6 æ ¸å¿ƒåˆå¹¶ç®—æ³•
- 19.7 GraphRAGçŸ¥è¯†å›¾è°±
- 19.8 æ–°å¢MdChapteråˆ‡ç‰‡æ–¹æ³•å®ç°

------

ä»¥ä¸‹æ˜¯æ­£æ–‡

# RAGFlow Python Backend Architecture Analysis

## 1. é¡¹ç›®æ¦‚è¿°

RAGFlowæ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦æ–‡æ¡£ç†è§£çš„å¼€æºRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰å¼•æ“ï¼Œåç«¯é‡‡ç”¨Pythonæ„å»ºï¼Œä¸»è¦ç”¨äºå®ç°æ™ºèƒ½æ–‡æ¡£å¤„ç†ã€çŸ¥è¯†åº“ç®¡ç†å’ŒAIå¯¹è¯åŠŸèƒ½ã€‚

## 2. æŠ€æœ¯æ ˆå’Œæ ¸å¿ƒæ¡†æ¶

### 2.1 Webæ¡†æ¶
- **Flask 3.0.3**: ä¸»Webæ¡†æ¶ï¼Œå¤„ç†HTTPè¯·æ±‚å’ŒAPIè·¯ç”±
- **Flask-CORS**: è·¨åŸŸèµ„æºå…±äº«æ”¯æŒ
- **Flask-Login**: ç”¨æˆ·è®¤è¯å’Œä¼šè¯ç®¡ç†
- **Flask-Session**: ä¼šè¯å­˜å‚¨ç®¡ç†
- **Flasgger**: Swagger APIæ–‡æ¡£ç”Ÿæˆ

### 2.2 æ•°æ®åº“å’ŒORM
- **Peewee 3.17.1**: è½»é‡çº§ORMï¼Œæ”¯æŒMySQLå’ŒPostgreSQL
- **PyMySQL**: MySQLæ•°æ®åº“è¿æ¥å™¨
- **PooledMySQLDatabase**: æ•°æ®åº“è¿æ¥æ± ç®¡ç†

### 2.3 å¼‚æ­¥å¤„ç†å’Œå¹¶å‘
- **Trio**: ç°ä»£å¼‚æ­¥I/Oæ¡†æ¶ï¼Œç”¨äºåå°ä»»åŠ¡å¤„ç†
- **å¤šè¿›ç¨‹æ¶æ„**: WebæœåŠ¡å™¨å’Œä»»åŠ¡æ‰§è¡Œå™¨åˆ†ç¦»éƒ¨ç½²

### 2.4 å­˜å‚¨å’Œç¼“å­˜
- **MinIO**: å¯¹è±¡å­˜å‚¨ï¼Œå¤„ç†æ–‡æ¡£å’Œå›¾ç‰‡æ–‡ä»¶
- **Redis/Valkey**: ç¼“å­˜å’Œæ¶ˆæ¯é˜Ÿåˆ—
- **Elasticsearch 8.12.1**: æ–‡æ¡£æœç´¢å¼•æ“
- **Infinity-SDK**: å‘é‡æ•°æ®åº“æ”¯æŒ

### 2.5 AIå’Œæœºå™¨å­¦ä¹ 
- **Transformers**: å¤§è¯­è¨€æ¨¡å‹é›†æˆ
- **NumPy/Pandas**: æ•°æ®å¤„ç†
- **ONNX Runtime**: æ¨¡å‹æ¨ç†
- **å¤šç§LLMé›†æˆ**: OpenAIã€Anthropicã€é€šä¹‰åƒé—®ã€æ™ºè°±AIç­‰

## 3. é¡¹ç›®ç›®å½•ç»“æ„åˆ†æ

### 3.1 æ ¸å¿ƒç›®å½•ç»“æ„
```
ragflow/
â”œâ”€â”€ api/                    # Flask Web APIå±‚
â”‚   â”œâ”€â”€ apps/              # è·¯ç”±æ¨¡å—
â”‚   â”œâ”€â”€ db/                # æ•°æ®æ¨¡å‹å’ŒæœåŠ¡å±‚
â”‚   â”œâ”€â”€ utils/             # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ ragflow_server.py  # WebæœåŠ¡å™¨å¯åŠ¨è„šæœ¬
â”œâ”€â”€ rag/                   # RAGæ ¸å¿ƒå¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ app/               # æ–‡æ¡£è§£æå™¨
â”‚   â”œâ”€â”€ llm/               # å¤§è¯­è¨€æ¨¡å‹å°è£…
â”‚   â”œâ”€â”€ nlp/               # è‡ªç„¶è¯­è¨€å¤„ç†
â”‚   â”œâ”€â”€ svr/               # åå°æœåŠ¡
â”‚   â””â”€â”€ utils/             # RAGå·¥å…·å‡½æ•°
â”œâ”€â”€ plugin/                # æ’ä»¶ç³»ç»Ÿ
â”œâ”€â”€ agent/                 # AIæ™ºèƒ½ä½“
â”œâ”€â”€ deepdoc/               # æ–‡æ¡£è§£æå¼•æ“
â”œâ”€â”€ graphrag/              # çŸ¥è¯†å›¾è°±RAG
â”œâ”€â”€ conf/                  # é…ç½®æ–‡ä»¶
â””â”€â”€ web/                   # å‰ç«¯Reactåº”ç”¨
```

### 3.2 å¯åŠ¨è„šæœ¬åˆ†æ

#### WebæœåŠ¡å™¨å¯åŠ¨ (`api/ragflow_server.py`)
- **ç«¯å£**: é»˜è®¤9380
- **åŠŸèƒ½**: åˆå§‹åŒ–Flaskåº”ç”¨ã€æ•°æ®åº“ã€æ’ä»¶ç®¡ç†å™¨
- **å…³é”®ç»„ä»¶**: 
  - LoginManagerç”¨æˆ·è®¤è¯
  - DocumentServiceè¿›åº¦æ›´æ–°çº¿ç¨‹
  - å…¨å±€æ’ä»¶ç®¡ç†å™¨åŠ è½½

#### ä»»åŠ¡æ‰§è¡Œå™¨å¯åŠ¨ (`rag/svr/task_executor.py`)
- **åŠŸèƒ½**: å¼‚æ­¥å¤„ç†æ–‡æ¡£è§£æã€å‘é‡åŒ–ã€ç´¢å¼•ä»»åŠ¡
- **æ¶æ„**: Trioåç¨‹æ± ï¼Œæ”¯æŒå¹¶å‘é™åˆ¶
- **ä»»åŠ¡ç±»å‹**: æ–‡æ¡£åˆ†å—ã€åµŒå…¥ç”Ÿæˆã€RAPTORèšç±»ã€GraphRAG

## 4. Flaskåº”ç”¨æ¶æ„

### 4.1 åº”ç”¨åˆå§‹åŒ– (`api/apps/__init__.py`)
- **è“å›¾æ³¨å†Œ**: è‡ªåŠ¨æ‰«æ`*_app.py`æ–‡ä»¶æ³¨å†Œè·¯ç”±
- **ä¸­é—´ä»¶é…ç½®**: CORSã€JSONç¼–ç å™¨ã€é”™è¯¯å¤„ç†
- **è®¤è¯ç³»ç»Ÿ**: JWT tokenå’ŒAPI keyåŒé‡è®¤è¯
- **Swaggeré›†æˆ**: è‡ªåŠ¨ç”ŸæˆAPIæ–‡æ¡£

### 4.2 ä¸»è¦è·¯ç”±æ¨¡å—
| æ¨¡å— | æ–‡ä»¶ | åŠŸèƒ½æè¿° |
|------|------|----------|
| ç”¨æˆ·ç®¡ç† | `user_app.py` | ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€ä¸ªäººä¿¡æ¯ç®¡ç† |
| çŸ¥è¯†åº“ | `kb_app.py` | çŸ¥è¯†åº“CRUDã€é…ç½®ç®¡ç† |
| æ–‡æ¡£ç®¡ç† | `document_app.py` | æ–‡æ¡£ä¸Šä¼ ã€è§£æã€åˆ é™¤ |
| å¯¹è¯åº”ç”¨ | `dialog_app.py` | AIåŠ©æ‰‹åˆ›å»ºã€é…ç½® |
| ä¼šè¯ç®¡ç† | `conversation_app.py` | å¯¹è¯ä¼šè¯ã€æ¶ˆæ¯å†å² |
| APIæ¥å£ | `api_app.py` | å¤–éƒ¨APIè°ƒç”¨æ¥å£ |
| æ™ºèƒ½ä½“ | `canvas_app.py` | AI Agentå·¥ä½œæµ |
| æ¨¡å‹ç®¡ç† | `llm_app.py` | å¤§è¯­è¨€æ¨¡å‹é…ç½® |

### 4.3 è®¤è¯æœºåˆ¶
- **Webç”¨æˆ·**: Flask-Login + JWT token
- **APIè°ƒç”¨**: Authorization header + API keyéªŒè¯
- **æƒé™æ§åˆ¶**: åŸºäºtenant_idçš„å¤šç§Ÿæˆ·éš”ç¦»

## 5. æ•°æ®åº“æ¶æ„

### 5.1 æ•°æ®æ¨¡å‹è®¾è®¡ (`api/db/db_models.py`)
- **ç”¨æˆ·ä½“ç³»**: Userã€Tenantã€UserTenantå…³è”è¡¨
- **çŸ¥è¯†åº“**: Knowledgebaseã€Documentã€Chunk
- **å¯¹è¯ç³»ç»Ÿ**: Dialogã€Conversationã€API4Conversation
- **ä»»åŠ¡ç®¡ç†**: Taskã€Fileã€File2Document
- **æ¨¡å‹é…ç½®**: LLMã€APIToken

### 5.2 æœåŠ¡å±‚æ¶æ„ (`api/db/services/`)
- **é€šç”¨æœåŠ¡**: `common_service.py` - åŸºç¡€CRUDæ“ä½œ
- **ä¸šåŠ¡æœåŠ¡**: æ¯ä¸ªæ¨¡å—ç‹¬ç«‹çš„æœåŠ¡ç±»
- **äº‹åŠ¡ç®¡ç†**: Peewee ORMè‡ªåŠ¨äº‹åŠ¡å¤„ç†
- **è¿æ¥æ± **: `PooledMySQLDatabase`ä¼˜åŒ–æ€§èƒ½

## 6. RAGæ ¸å¿ƒæ¨¡å—

### 6.1 æ–‡æ¡£è§£æå™¨ (`rag/app/`)
| è§£æå™¨ | æ”¯æŒæ ¼å¼ | ç‰¹æ®ŠåŠŸèƒ½ |
|--------|----------|----------|
| `naive.py` | é€šç”¨æ–‡æœ¬ | åŸºç¡€åˆ†å— |
| `pdf_parser.py` | PDF | OCRã€è¡¨æ ¼è¯†åˆ« |
| `docx_parser.py` | Word | æ ¼å¼ä¿æŒ |
| `excel_parser.py` | Excel | è¡¨æ ¼ç»“æ„åŒ– |
| `picture.py` | å›¾ç‰‡ | è§†è§‰é—®ç­” |
| `audio.py` | éŸ³é¢‘ | è¯­éŸ³è½¬æ–‡æœ¬ |

### 6.2 å¤§è¯­è¨€æ¨¡å‹å°è£… (`rag/llm/`)
- **chat_model.py**: å¯¹è¯æ¨¡å‹ç»Ÿä¸€æ¥å£
- **embedding_model.py**: å‘é‡åµŒå…¥æ¨¡å‹
- **rerank_model.py**: æ£€ç´¢é‡æ’åºæ¨¡å‹
- **tts_model.py**: æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹

### 6.3 è‡ªç„¶è¯­è¨€å¤„ç† (`rag/nlp/`)
- **rag_tokenizer.py**: ä¸­æ–‡åˆ†è¯å’Œæ ‡è®°åŒ–
- **search.py**: æœç´¢ç®—æ³•å®ç°
- **query.py**: æŸ¥è¯¢ç†è§£å’Œä¼˜åŒ–

### 6.4 åå°æœåŠ¡ (`rag/svr/`)
- **task_executor.py**: ä¸»ä»»åŠ¡æ‰§è¡Œå™¨
- **å·¥ä½œæµç¨‹**: æ–‡æ¡£ä¸Šä¼ â†’è§£æâ†’åˆ†å—â†’å‘é‡åŒ–â†’ç´¢å¼•
- **å¹¶å‘æ§åˆ¶**: Trioä¿¡å·é‡é™åˆ¶èµ„æºä½¿ç”¨

## 7. å¯¹è¯ç³»ç»Ÿæ ¸å¿ƒæµç¨‹

### 7.1 å¯¹è¯å¤„ç†æµç¨‹ (`api/db/services/dialog_service.py`)
1. **æ¶ˆæ¯é¢„å¤„ç†**: è¿‡æ»¤ç³»ç»Ÿæ¶ˆæ¯ï¼Œç”Ÿæˆmessage_id
2. **æ¨¡å‹åˆå§‹åŒ–**: è·å–LLMã€åµŒå…¥ã€é‡æ’åºæ¨¡å‹
3. **æŸ¥è¯¢ä¼˜åŒ–**: å¤šè½®å¯¹è¯ä¼˜åŒ–ã€å…³é”®è¯æå–
4. **çŸ¥è¯†æ£€ç´¢**: å‘é‡æœç´¢ã€ç½‘ç»œæœç´¢ã€çŸ¥è¯†å›¾è°±
5. **å“åº”ç”Ÿæˆ**: åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå›ç­”
6. **å¼•ç”¨å¤„ç†**: è‡ªåŠ¨æ ‡æ³¨æ–‡æ¡£æ¥æº

### 7.2 æ£€ç´¢å¢å¼ºæœºåˆ¶
- **å‘é‡æ£€ç´¢**: åŸºäºembeddingçš„è¯­ä¹‰æœç´¢
- **é‡æ’åº**: äºŒæ¬¡æ’åºæå‡ç›¸å…³æ€§
- **å¼•ç”¨ç³»ç»Ÿ**: è‡ªåŠ¨ç”Ÿæˆå¯è¿½æº¯çš„å¼•ç”¨
- **æµå¼è¾“å‡º**: æ”¯æŒSSEå®æ—¶å“åº”

## 8. æ’ä»¶ç³»ç»Ÿ

### 8.1 æ’ä»¶æ¡†æ¶ (`plugin/`)
- **plugin_manager.py**: æ’ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **llm_tool_plugin.py**: LLMå·¥å…·è°ƒç”¨æ’ä»¶
- **çƒ­æ’æ‹”**: è¿è¡Œæ—¶åŠ¨æ€åŠ è½½æ’ä»¶

### 8.2 æ™ºèƒ½ä½“ç³»ç»Ÿ (`agent/`)
- **Canvaså·¥ä½œæµ**: å›¾å½¢åŒ–AIå·¥ä½œæµç¼–æ’
- **ç»„ä»¶åŒ–è®¾è®¡**: å¯æ‹–æ‹½çš„åŠŸèƒ½ç»„ä»¶
- **æ¨¡æ¿ç³»ç»Ÿ**: é¢„å®šä¹‰çš„æ™ºèƒ½ä½“æ¨¡æ¿

## 9. é…ç½®å’Œéƒ¨ç½²

### 9.1 é…ç½®æ–‡ä»¶ (`conf/service_conf.yaml`)
```yaml
ragflow:
  host: 0.0.0.0
  http_port: 9380
mysql:
  host: '172.20.208.1'
  port: 3306
  name: 'rag_flow'
minio:
  host: '172.20.208.1:9001'
redis:
  host: '127.0.0.1:7001'
es:
  hosts: 'https://172.20.208.1:9200'
```

### 9.2 ä¾èµ–ç®¡ç†
- **åŒ…ç®¡ç†å™¨**: UV (å¿«é€ŸPythonåŒ…ç®¡ç†)
- **Pythonç‰ˆæœ¬**: >=3.10, <3.13
- **ä¸»è¦ä¾èµ–**: 100+ä¸ªåŒ…ï¼Œè¦†ç›–AIã€æ•°æ®å¤„ç†ã€Webæ¡†æ¶

### 9.3 å¯åŠ¨å‘½ä»¤
```bash
# WebæœåŠ¡å™¨
export NLTK_DATA="/path/to/nltk_data"
PYTHONPATH=. poetry run python api/ragflow_server.py

# ä»»åŠ¡æ‰§è¡Œå™¨
PYTHONPATH=. poetry run python rag/svr/task_executor.py
```

## 10. å…³é”®ç‰¹æ€§

### 10.1 å¤šç§Ÿæˆ·æ¶æ„
- ç§Ÿæˆ·éš”ç¦»çš„æ•°æ®å’Œæƒé™
- ç‹¬ç«‹çš„çŸ¥è¯†åº“å’Œæ¨¡å‹é…ç½®
- èµ„æºä½¿ç”¨é‡ç»Ÿè®¡å’Œé™åˆ¶

### 10.2 é«˜å¹¶å‘å¤„ç†
- Trioå¼‚æ­¥æ¡†æ¶æ”¯æŒé«˜å¹¶å‘
- è¿æ¥æ± ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½
- ä»»åŠ¡é˜Ÿåˆ—é¿å…é˜»å¡

### 10.3 å¯æ‰©å±•æ€§
- å¾®æœåŠ¡æ¶æ„æ”¯æŒæ°´å¹³æ‰©å±•
- æ’ä»¶ç³»ç»Ÿæ”¯æŒåŠŸèƒ½æ‰©å±•
- å¤šç§å­˜å‚¨åç«¯æ”¯æŒ

### 10.4 ä¼ä¸šçº§ç‰¹æ€§
- å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§
- APIé™æµå’Œé‰´æƒ
- æ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤

## 11. æ€§èƒ½ä¼˜åŒ–

### 11.1 ç¼“å­˜ç­–ç•¥
- Redisç¼“å­˜çƒ­ç‚¹æ•°æ®
- LLMè°ƒç”¨ç»“æœç¼“å­˜
- å‘é‡è®¡ç®—ç»“æœç¼“å­˜

### 11.2 èµ„æºç®¡ç†
- å†…å­˜ä½¿ç”¨ç›‘æ§(tracemalloc)
- ä»»åŠ¡å¹¶å‘é™åˆ¶
- æ•°æ®åº“è¿æ¥æ± 

è¿™ä¸ªæ¶æ„è®¾è®¡ä½“ç°äº†ç°ä»£ä¼ä¸šçº§RAGç³»ç»Ÿçš„æœ€ä½³å®è·µï¼Œå…·å¤‡é«˜æ€§èƒ½ã€é«˜å¯ç”¨ã€æ˜“æ‰©å±•çš„ç‰¹ç‚¹ã€‚

## 12. å‰ç«¯APIæ¥å£æ¸…å•

### 12.1 ç”¨æˆ·ç®¡ç†æ¥å£ (`/v1/user/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|
| `/login` | POST | ç”¨æˆ·ç™»å½•éªŒè¯ | æ—  |
| `/logout` | GET | ç”¨æˆ·é€€å‡ºç™»å½• | @login_required |
| `/register` | POST | ç”¨æˆ·æ³¨å†Œ | @validate_request |
| `/setting` | POST | æ›´æ–°ç”¨æˆ·è®¾ç½® | @login_required |
| `/info` | GET | è·å–ç”¨æˆ·ä¿¡æ¯ | @login_required |
| `/tenant_info` | GET | è·å–ç§Ÿæˆ·ä¿¡æ¯ | @login_required |
| `/set_tenant_info` | POST | è®¾ç½®ç§Ÿæˆ·é…ç½® | @login_required |
| `/login/channels` | GET | è·å–OAuthæ¸ é“ | æ—  |
| `/oauth/callback/<channel>` | GET | OAuthå›è°ƒå¤„ç† | æ—  |

### 12.2 çŸ¥è¯†åº“ç®¡ç†æ¥å£ (`/v1/kb/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/create` | POST | åˆ›å»ºçŸ¥è¯†åº“ | name | @login_required |
| `/update` | POST | æ›´æ–°çŸ¥è¯†åº“ | kb_id, name, description | @login_required |
| `/detail` | GET | è·å–çŸ¥è¯†åº“è¯¦æƒ… | kb_id | @login_required |
| `/list` | POST | çŸ¥è¯†åº“åˆ—è¡¨ | page, page_size, keywords | @login_required |
| `/rm` | POST | åˆ é™¤çŸ¥è¯†åº“ | kb_id | @login_required |
| `/<kb_id>/tags` | GET | è·å–çŸ¥è¯†åº“æ ‡ç­¾ | æ—  | @login_required |
| `/<kb_id>/knowledge_graph` | GET | è·å–çŸ¥è¯†å›¾è°± | æ—  | @login_required |

### 12.3 æ–‡æ¡£ç®¡ç†æ¥å£ (`/v1/document/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/upload` | POST | æ–‡æ¡£ä¸Šä¼  | kb_id, file | @login_required |
| `/web_crawl` | POST | ç½‘é¡µæŠ“å– | kb_id, url | @login_required |
| `/list` | POST | æ–‡æ¡£åˆ—è¡¨ | kb_id, page, page_size | @login_required |
| `/rm` | POST | åˆ é™¤æ–‡æ¡£ | doc_id | @login_required |
| `/run` | POST | å¯åŠ¨æ–‡æ¡£è§£æ | doc_ids, run | @login_required |
| `/change_status` | POST | å˜æ›´æ–‡æ¡£çŠ¶æ€ | doc_id, status | @login_required |
| `/rename` | POST | é‡å‘½åæ–‡æ¡£ | doc_id, name | @login_required |
| `/change_parser` | POST | æ›´æ”¹è§£æå™¨ | doc_id, parser_id | @login_required |
| `/get/<doc_id>` | GET | ä¸‹è½½æ–‡æ¡£ | æ—  | æ—  |
| `/image/<image_id>` | GET | è·å–æ–‡æ¡£å›¾ç‰‡ | æ—  | æ—  |

### 12.4 å¯¹è¯åº”ç”¨æ¥å£ (`/v1/dialog/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/set` | POST | åˆ›å»º/æ›´æ–°å¯¹è¯åº”ç”¨ | name, kb_ids, llm_id | @login_required |
| `/get` | GET | è·å–å¯¹è¯åº”ç”¨ | dialog_id | @login_required |
| `/list` | GET | å¯¹è¯åº”ç”¨åˆ—è¡¨ | æ—  | @login_required |
| `/rm` | POST | åˆ é™¤å¯¹è¯åº”ç”¨ | dialog_ids | @login_required |

### 12.5 ä¼šè¯ç®¡ç†æ¥å£ (`/v1/conversation/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/set` | POST | åˆ›å»º/æ›´æ–°ä¼šè¯ | conversation_id, dialog_id | @login_required |
| `/get` | GET | è·å–ä¼šè¯è¯¦æƒ… | conversation_id | @login_required |
| `/list` | GET | ä¼šè¯åˆ—è¡¨ | dialog_id | @login_required |
| `/rm` | POST | åˆ é™¤ä¼šè¯ | conversation_ids | @login_required |
| `/completion` | POST | å¯¹è¯è¡¥å…¨ | conversation_id, messages | @login_required |
| `/ask` | POST | å¿«é€Ÿé—®ç­” | question, kb_ids | @login_required |
| `/mindmap` | POST | ç”Ÿæˆæ€ç»´å¯¼å›¾ | question, kb_ids | @login_required |

### 12.6 å¤–éƒ¨APIæ¥å£ (`/api/v1/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/new_token` | POST | åˆ›å»ºAPI Token | dialog_id | @login_required |
| `/new_conversation` | GET | åˆ›å»ºä¼šè¯ | user_id | API Token |
| `/completion` | POST | APIå¯¹è¯è¡¥å…¨ | conversation_id, messages | API Token |
| `/document/upload` | POST | APIæ–‡æ¡£ä¸Šä¼  | kb_name, file | API Token |
| `/retrieval` | POST | å‘é‡æ£€ç´¢ | kb_id, question | API Token |
| `/list_chunks` | POST | è·å–æ–‡æ¡£å— | doc_id/doc_name | API Token |

### 12.7 æ™ºèƒ½ä½“æ¥å£ (`/v1/canvas/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/templates` | GET | è·å–æ¨¡æ¿åˆ—è¡¨ | æ—  | @login_required |
| `/list` | GET | æ™ºèƒ½ä½“åˆ—è¡¨ | æ—  | @login_required |
| `/set` | POST | åˆ›å»º/æ›´æ–°æ™ºèƒ½ä½“ | dsl, title | @login_required |
| `/get/<canvas_id>` | GET | è·å–æ™ºèƒ½ä½“è¯¦æƒ… | æ—  | @login_required |
| `/completion` | POST | è¿è¡Œæ™ºèƒ½ä½“ | id, message | @login_required |
| `/debug` | POST | è°ƒè¯•ç»„ä»¶ | id, component_id | @login_required |

### 12.8 æ¨¡å‹ç®¡ç†æ¥å£ (`/v1/llm/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/factories` | GET | è·å–æ¨¡å‹å‚å•† | æ—  | @login_required |
| `/set_api_key` | POST | è®¾ç½®APIå¯†é’¥ | llm_factory, api_key | @login_required |
| `/add_llm` | POST | æ·»åŠ æ¨¡å‹ | llm_factory, llm_name | @login_required |
| `/delete_llm` | POST | åˆ é™¤æ¨¡å‹ | llm_factory, llm_name | @login_required |
| `/my_llms` | GET | æˆ‘çš„æ¨¡å‹åˆ—è¡¨ | æ—  | @login_required |
| `/list` | GET | å¯ç”¨æ¨¡å‹åˆ—è¡¨ | model_type | @login_required |

### 12.9 æ–‡æ¡£å—ç®¡ç†æ¥å£ (`/v1/chunk/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/list` | POST | æ–‡æ¡£å—åˆ—è¡¨ | doc_id, page, size | @login_required |
| `/get` | GET | è·å–æ–‡æ¡£å— | chunk_id | @login_required |
| `/set` | POST | æ›´æ–°æ–‡æ¡£å— | chunk_id, content | @login_required |
| `/create` | POST | åˆ›å»ºæ–‡æ¡£å— | doc_id, content | @login_required |
| `/rm` | POST | åˆ é™¤æ–‡æ¡£å— | chunk_ids | @login_required |
| `/retrieval_test` | POST | æ£€ç´¢æµ‹è¯• | kb_id, question | @login_required |

### 12.10 æ–‡ä»¶ç®¡ç†æ¥å£ (`/v1/file/`)
| æ¥å£ | æ–¹æ³• | åŠŸèƒ½æè¿° | ä¸»è¦å‚æ•° | è®¤è¯è¦æ±‚ |
|------|------|----------|----------|----------|
| `/upload` | POST | æ–‡ä»¶ä¸Šä¼  | parent_id, file | @login_required |
| `/create` | POST | åˆ›å»ºæ–‡ä»¶å¤¹ | name, parent_id | @login_required |
| `/list` | GET | æ–‡ä»¶åˆ—è¡¨ | parent_id, keywords | @login_required |
| `/rm` | POST | åˆ é™¤æ–‡ä»¶ | file_ids | @login_required |
| `/rename` | POST | é‡å‘½åæ–‡ä»¶ | file_id, name | @login_required |
| `/mv` | POST | ç§»åŠ¨æ–‡ä»¶ | src_file_ids, dest_file_id | @login_required |

## 13. æ•°æ®åº“è¡¨ç»“æ„è®¾è®¡

### 13.1 æ•°æ®åº“è¡¨ç»“æ„æ¦‚è§ˆ

RAGFlowé¡¹ç›®é‡‡ç”¨å…³ç³»å‹æ•°æ®åº“(MySQL/PostgreSQL)å­˜å‚¨ä¸šåŠ¡æ•°æ®ï¼Œä¸»è¦åŒ…å«20ä¸ªæ ¸å¿ƒæ•°æ®è¡¨ã€‚è¯¦ç»†çš„è¡¨ç»“æ„åˆ†ææ–‡æ¡£ä½äºé¡¹ç›®æ ¹ç›®å½•ï¼š

**å‚è€ƒæ–‡æ¡£**: `ragflowå­¦ä¹ èµ„æ–™/ragflow-è¡¨ç»“æ„åˆ†æ-å¤§æ¨¡å‹.md`

è¯¥æ–‡æ¡£åŒ…å«å®Œæ•´çš„æ•°æ®åº“è®¾è®¡åˆ†æï¼Œæ¶µç›–ï¼š
- è¡¨æ¸…å•å’Œå­—æ®µå®šä¹‰
- ä¸»é”®å¤–é”®å…³ç³»
- ä¸šåŠ¡åœºæ™¯å’Œæ•°æ®æµè½¬
- å¤šç§Ÿæˆ·æ¶æ„è®¾è®¡

### 13.2 æ ¸å¿ƒè¡¨ç»“æ„å…³ç³»

```
Tenant (ç§Ÿæˆ·)
â”œâ”€â”€ User (ç”¨æˆ·) â†â†’ UserTenant (ç”¨æˆ·-ç§Ÿæˆ·å…³è”)
â”œâ”€â”€ Knowledgebase (çŸ¥è¯†åº“)
â”‚   â”œâ”€â”€ Document (æ–‡æ¡£) â†â†’ File2Document â†â†’ File (æ–‡ä»¶)
â”‚   â””â”€â”€ Task (è§£æä»»åŠ¡)
â”œâ”€â”€ Dialog (å¯¹è¯åº”ç”¨)
â”‚   â”œâ”€â”€ Conversation (ä¼šè¯è®°å½•)
â”‚   â””â”€â”€ API4Conversation (APIä¼šè¯è®°å½•)
â”œâ”€â”€ TenantLLM (ç§Ÿæˆ·-æ¨¡å‹å…³è”) â†â†’ LLM (å¤§è¯­è¨€æ¨¡å‹)
â”œâ”€â”€ APIToken (APIè®¿é—®ä»¤ç‰Œ)
â””â”€â”€ UserCanvas (æ™ºèƒ½ä½“å·¥ä½œæµ)
    â””â”€â”€ UserCanvasVersion (å·¥ä½œæµç‰ˆæœ¬)
```

### 13.3 å…³é”®ä¸šåŠ¡è¡¨è¯´æ˜

#### å¤šç§Ÿæˆ·ä½“ç³»
- **tenant**: ç§Ÿæˆ·åŸºç¡€ä¿¡æ¯å’Œé»˜è®¤æ¨¡å‹é…ç½®
- **user**: ç”¨æˆ·è´¦æˆ·ä¿¡æ¯å’Œåå¥½è®¾ç½®  
- **user_tenant**: ç”¨æˆ·åœ¨ç§Ÿæˆ·ä¸­çš„è§’è‰²å…³è”(owner/admin/normal)

#### çŸ¥è¯†åº“ä½“ç³»
- **knowledgebase**: çŸ¥è¯†åº“å…ƒæ•°æ®å’Œè§£æé…ç½®
- **document**: æ–‡æ¡£ä¿¡æ¯ã€è§£æè¿›åº¦ã€ç»Ÿè®¡æ•°æ®
- **file**: åŸå§‹æ–‡ä»¶çš„ç›®å½•æ ‘ç»“æ„
- **file2document**: æ–‡ä»¶ä¸æ–‡æ¡£çš„å¤šå¯¹å¤šæ˜ å°„
- **task**: æ–‡æ¡£è§£æã€å‘é‡åŒ–ã€ç´¢å¼•ä»»åŠ¡

#### å¯¹è¯ä½“ç³»
- **dialog**: å¯¹è¯åº”ç”¨é…ç½®(LLMã€æç¤ºè¯ã€æ£€ç´¢ç­–ç•¥)
- **conversation**: å‰ç«¯UIå¯¹è¯è®°å½•
- **api_4_conversation**: APIæ¥å£å¯¹è¯è®°å½•
- **api_token**: å¤–éƒ¨APIè®¿é—®ä»¤ç‰Œç®¡ç†

#### æ¨¡å‹ä½“ç³»
- **llm_factories**: æ¨¡å‹ä¾›åº”å•†æ³¨å†Œè¡¨
- **llm**: å¹³å°å¯ç”¨æ¨¡å‹æ¸…å•
- **tenant_llm**: ç§Ÿæˆ·çš„æ¨¡å‹APIå¯†é’¥å’Œé…ç½®

#### æ™ºèƒ½ä½“ä½“ç³»
- **canvas_template**: å†…ç½®æ™ºèƒ½ä½“æ¨¡æ¿
- **user_canvas**: ç”¨æˆ·è‡ªå®šä¹‰æ™ºèƒ½ä½“å·¥ä½œæµ
- **user_canvas_version**: æ™ºèƒ½ä½“ç‰ˆæœ¬å†å²ç®¡ç†

## 14. çŸ¥è¯†åº“æ•°æ®é›†ç®¡ç†æµç¨‹

### 14.1 çŸ¥è¯†åº“åˆ›å»ºæµç¨‹

#### æ¥å£è·¯å¾„: `POST /v1/kb/create`
#### æ ¸å¿ƒä»£ç : `api/apps/kb_app.py:create()`

**æµç¨‹æ­¥éª¤:**
1. **æƒé™éªŒè¯**: æ£€æŸ¥ç”¨æˆ·ç™»å½•çŠ¶æ€å’Œç§Ÿæˆ·æƒé™
2. **å‚æ•°éªŒè¯**: éªŒè¯çŸ¥è¯†åº“åç§°å”¯ä¸€æ€§
3. **æ•°æ®åº“æ“ä½œ**:
   ```python
   # åˆ›å»ºçŸ¥è¯†åº“è®°å½•
   KnowledgebaseService.save(
       name=name,
       tenant_id=tenant_id,
       created_by=user_id,
       language="Chinese",
       parser_id="general"
   )
   ```
4. **åˆå§‹åŒ–é…ç½®**: è®¾ç½®é»˜è®¤è§£æå™¨å’ŒåµŒå…¥æ¨¡å‹
5. **ç´¢å¼•åˆ›å»º**: åœ¨Elasticsearch/Infinityä¸­åˆ›å»ºå¯¹åº”ç´¢å¼•

**æ¶‰åŠæ•°æ®è¡¨:**
- `knowledgebase`: æ’å…¥çŸ¥è¯†åº“è®°å½•
- `user_tenant`: éªŒè¯ç”¨æˆ·æƒé™

### 14.2 æ–‡æ¡£ä¸Šä¼ æµç¨‹

#### æ¥å£è·¯å¾„: `POST /v1/document/upload`
#### æ ¸å¿ƒä»£ç : `api/apps/document_app.py:upload()`

**æµç¨‹æ­¥éª¤:**
1. **æ–‡ä»¶éªŒè¯**:
   ```python
   # æ–‡ä»¶ç±»å‹å’Œå¤§å°æ£€æŸ¥
   filetype = filename_type(filename)
   if not filetype:
       return error("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
   ```

2. **å­˜å‚¨ä¸Šä¼ **:
   ```python
   # ä¸Šä¼ åˆ°MinIOå¯¹è±¡å­˜å‚¨
   location = filename
   while STORAGE_IMPL.obj_exist(kb_id, location):
       location += "_"  # é¿å…æ–‡ä»¶åå†²çª
   STORAGE_IMPL.put(kb_id, location, blob)
   ```

3. **æ•°æ®åº“è®°å½•**:
   ```python
   # åˆ›å»ºæ–‡æ¡£è®°å½•
   doc = {
       "id": get_uuid(),
       "kb_id": kb_id,
       "parser_id": kb.parser_id,
       "name": filename,
       "location": location,
       "size": len(blob),
       "thumbnail": thumbnail(filename, blob)
   }
   DocumentService.insert(doc)
   ```

4. **æ–‡ä»¶å…³è”**:
   ```python
   # åˆ›å»ºæ–‡ä»¶-æ–‡æ¡£å…³è”
   FileService.add_file_from_kb(doc, folder_id, tenant_id)
   File2DocumentService.create_association(file_id, doc_id)
   ```

**æ¶‰åŠæ•°æ®è¡¨:**
- `document`: æ’å…¥æ–‡æ¡£è®°å½•
- `file`: æ’å…¥æ–‡ä»¶è®°å½•  
- `file2document`: åˆ›å»ºæ–‡ä»¶-æ–‡æ¡£å…³è”
- `knowledgebase`: æ›´æ–°æ–‡æ¡£ç»Ÿè®¡

### 14.3 æ–‡æ¡£è§£æå’Œåˆ†å—æµç¨‹

#### æ ¸å¿ƒä»£ç : `rag/svr/task_executor.py:do_handle_task()`

**æµç¨‹æ­¥éª¤:**

1. **ä»»åŠ¡é˜Ÿåˆ—å¤„ç†**:
   ```python
   # ä»Redisé˜Ÿåˆ—è·å–è§£æä»»åŠ¡
   redis_msg, task = await collect()
   if not task:
       return
   ```

2. **æ–‡ä»¶è·å–**:
   ```python
   # ä»MinIOè·å–æ–‡ä»¶å†…å®¹
   bucket, name = File2DocumentService.get_storage_address(doc_id)
   binary = await get_storage_binary(bucket, name)
   ```

3. **æ–‡æ¡£è§£æ**:
   ```python
   # æ ¹æ®è§£æå™¨ç±»å‹è°ƒç”¨å¯¹åº”è§£æå™¨
   chunker = FACTORY[task["parser_id"].lower()]
   chunks = await trio.to_thread.run_sync(
       lambda: chunker.chunk(
           task["name"], 
           binary=binary,
           parser_config=task["parser_config"]
       )
   )
   ```

4. **å‘é‡åŒ–å¤„ç†**:
   ```python
   # ç”Ÿæˆæ–‡æ¡£å—åµŒå…¥å‘é‡
   embedding_model = LLMBundle(tenant_id, LLMType.EMBEDDING)
   token_count, vector_size = await embedding(
       chunks, embedding_model, parser_config
   )
   ```

5. **ç´¢å¼•å­˜å‚¨**:
   ```python
   # æ‰¹é‡æ’å…¥Elasticsearch/Infinity
   for b in range(0, len(chunks), es_bulk_size):
       result = await trio.to_thread.run_sync(
           lambda: settings.docStoreConn.insert(
               chunks[b:b + es_bulk_size],
               search.index_name(tenant_id),
               kb_id
           )
       )
   ```

**è§£æå™¨ç±»å‹:**
- `naive`: é€šç”¨æ–‡æœ¬åˆ†å—
- `pdf_parser`: PDF OCRå’Œè¡¨æ ¼è¯†åˆ«
- `docx_parser`: Wordæ–‡æ¡£æ ¼å¼ä¿æŒ
- `excel_parser`: Excelè¡¨æ ¼ç»“æ„åŒ–
- `picture`: å›¾ç‰‡è§†è§‰é—®ç­”
- `audio`: éŸ³é¢‘è½¬æ–‡æœ¬

**æ¶‰åŠæ•°æ®è¡¨:**
- `task`: æ›´æ–°ä»»åŠ¡è¿›åº¦å’ŒçŠ¶æ€
- `document`: æ›´æ–°è§£æè¿›åº¦å’Œç»Ÿè®¡
- å¤–éƒ¨å­˜å‚¨: Elasticsearch/Infinityå‘é‡ç´¢å¼•

### 14.4 æ–‡æ¡£åˆ é™¤æµç¨‹è¯¦è§£

#### 14.4.1 Webæ¥å£åˆ é™¤: `POST /v1/document/rm`
#### æ ¸å¿ƒä»£ç : `api/apps/document_app.py:rm()`

**åˆ é™¤æµç¨‹:**

1. **æƒé™éªŒè¯**:
   ```python
   for doc_id in doc_ids:
       if not DocumentService.accessible4deletion(doc_id, current_user.id):
           return get_json_result(data=False, message="No authorization.")
   ```

2. **ä»»åŠ¡æ¸…ç†**:
   ```python
   # åˆ é™¤ç›¸å…³çš„è§£æä»»åŠ¡
   TaskService.filter_delete([Task.doc_id == doc_id])
   ```

3. **æ•°æ®åº“åˆ é™¤**:
   ```python
   # è°ƒç”¨æ ¸å¿ƒåˆ é™¤æ–¹æ³•
   if not DocumentService.remove_document(doc, tenant_id):
       return get_data_error_result(message="Database error!")
   ```

4. **æ–‡ä»¶å…³è”æ¸…ç†**:
   ```python
   # åˆ é™¤æ–‡ä»¶-æ–‡æ¡£å…³è”
   f2d = File2DocumentService.get_by_document_id(doc_id)
   FileService.filter_delete([File.id == f2d[0].file_id])
   File2DocumentService.delete_by_document_id(doc_id)
   ```

5. **å­˜å‚¨æ¸…ç†**:
   ```python
   # åˆ é™¤MinIOä¸­çš„åŸå§‹æ–‡ä»¶
   if deleted_file_count > 0:
       STORAGE_IMPL.rm(bucket, name)
   ```

#### 14.4.2 APIæ¥å£åˆ é™¤: `DELETE /api/v1/document`
#### æ ¸å¿ƒä»£ç : `api/apps/api_app.py:document_rm()`

**APIåˆ é™¤æµç¨‹:**
1. **API TokenéªŒè¯**: éªŒè¯Authorization headerä¸­çš„APIå¯†é’¥
2. **æ–‡æ¡£å®šä½**: æ”¯æŒé€šè¿‡doc_namesæˆ–doc_idså®šä½æ–‡æ¡£
3. **æ‰¹é‡åˆ é™¤**: è°ƒç”¨ç›¸åŒçš„æ ¸å¿ƒåˆ é™¤é€»è¾‘

#### 14.4.3 æ ¸å¿ƒåˆ é™¤æ–¹æ³•: `DocumentService.remove_document()`
#### æ ¸å¿ƒä»£ç : `api/db/services/document_service.py:remove_document()`

**è¯¦ç»†åˆ é™¤æ­¥éª¤:**

1. **æ¸…ç†ç»Ÿè®¡æ•°æ®**:
   ```python
   cls.clear_chunk_num(doc.id)
   ```

2. **åˆ†é¡µè·å–æ‰€æœ‰æ–‡æ¡£å—**:
   ```python
   page = 0
   page_size = 1000
   all_chunk_ids = []
   while True:
       chunks = settings.docStoreConn.search(
           ["img_id"], [], {"doc_id": doc.id}, [],
           OrderByExpr(), page * page_size, page_size,
           search.index_name(tenant_id), [doc.kb_id]
       )
       chunk_ids = settings.docStoreConn.getChunkIds(chunks)
       if not chunk_ids:
           break
       all_chunk_ids.extend(chunk_ids)
       page += 1
   ```

3. **åˆ é™¤å…³è”å›¾ç‰‡**:
   ```python
   # åˆ é™¤æ–‡æ¡£å—ä¸­çš„å›¾ç‰‡æ–‡ä»¶
   for cid in all_chunk_ids:
       if STORAGE_IMPL.obj_exist(doc.kb_id, cid):
           STORAGE_IMPL.rm(doc.kb_id, cid)
   
   # åˆ é™¤æ–‡æ¡£ç¼©ç•¥å›¾
   if doc.thumbnail and not doc.thumbnail.startswith(IMG_BASE64_PREFIX):
       if STORAGE_IMPL.obj_exist(doc.kb_id, doc.thumbnail):
           STORAGE_IMPL.rm(doc.kb_id, doc.thumbnail)
   ```

4. **åˆ é™¤å‘é‡ç´¢å¼•**:
   ```python
   # ä»Elasticsearch/Infinityåˆ é™¤æ‰€æœ‰ç›¸å…³chunk
   settings.docStoreConn.delete(
       {"doc_id": doc.id},
       search.index_name(tenant_id),
       doc.kb_id
   )
   ```

5. **å¤„ç†çŸ¥è¯†å›¾è°±**:
   ```python
   # å¦‚æœæ–‡æ¡£åŒ…å«çŸ¥è¯†å›¾è°±ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
   graph_source = settings.docStoreConn.getFields(...)
   if len(graph_source) > 0 and doc.id in list(graph_source.values())[0]["source_id"]:
       # æ›´æ–°çŸ¥è¯†å›¾è°±ä¸­çš„source_idå¼•ç”¨
       settings.docStoreConn.update(
           {"kb_id": doc.kb_id, "source_id": doc.id},
           {"remove": {"source_id": doc.id}},
           search.index_name(tenant_id), doc.kb_id
       )
       # åˆ é™¤å­¤ç«‹çš„çŸ¥è¯†å›¾è°±èŠ‚ç‚¹
       settings.docStoreConn.delete(
           {"kb_id": doc.kb_id, "must_not": {"exists": "source_id"}},
           search.index_name(tenant_id), doc.kb_id
       )
   ```

6. **åˆ é™¤æ•°æ®åº“è®°å½•**:
   ```python
   return cls.delete_by_id(doc.id)
   ```

**æ¶‰åŠçš„å­˜å‚¨æ¸…ç†:**
- **MySQLæ•°æ®åº“**: documentã€taskã€fileã€file2documentè¡¨
- **MinIOå¯¹è±¡å­˜å‚¨**: åŸå§‹æ–‡æ¡£æ–‡ä»¶ã€ç¼©ç•¥å›¾ã€chunkå…³è”å›¾ç‰‡
- **å‘é‡æ•°æ®åº“**: Elasticsearch/Infinityä¸­çš„æ–‡æ¡£å—ç´¢å¼•
- **çŸ¥è¯†å›¾è°±**: ç›¸å…³çš„å®ä½“ã€å…³ç³»ã€å­å›¾æ•°æ®

### 14.5 çŸ¥è¯†åº“åˆ é™¤æµç¨‹

#### æ¥å£è·¯å¾„: `POST /v1/kb/rm`
#### æ ¸å¿ƒä»£ç : `api/apps/kb_app.py:rm()`

**åˆ é™¤æµç¨‹:**
1. **çº§è”åˆ é™¤æ–‡æ¡£**: åˆ é™¤çŸ¥è¯†åº“ä¸‹æ‰€æœ‰æ–‡æ¡£åŠå…¶å…³è”æ•°æ®
2. **æ¸…ç†å‘é‡ç´¢å¼•**: åˆ é™¤Elasticsearchä¸­çš„æ•´ä¸ªç´¢å¼•
3. **åˆ é™¤çŸ¥è¯†åº“è®°å½•**: ä»æ•°æ®åº“åˆ é™¤çŸ¥è¯†åº“å…ƒæ•°æ®
4. **æ›´æ–°ç§Ÿæˆ·ç»Ÿè®¡**: æ›´æ–°ç§Ÿæˆ·çš„çŸ¥è¯†åº“æ•°é‡ç»Ÿè®¡

**æ•°æ®æ¸…ç†èŒƒå›´:**
- æ‰€æœ‰ç›¸å…³æ–‡æ¡£å’Œæ–‡ä»¶
- å‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±
- API Tokenå…³è”
- å¯¹è¯åº”ç”¨ä¸­çš„kb_idså¼•ç”¨

### 14.6 é”™è¯¯å¤„ç†å’Œå›æ»šæœºåˆ¶

**äº‹åŠ¡ä¿æŠ¤:**
- æ•°æ®åº“æ“ä½œä½¿ç”¨äº‹åŠ¡ç¡®ä¿ä¸€è‡´æ€§
- å­˜å‚¨æ“ä½œå¤±è´¥æ—¶å›æ»šæ•°æ®åº“å˜æ›´
- å¼‚æ­¥ä»»åŠ¡å¤±è´¥æ—¶æ›´æ–°çŠ¶æ€ä¸ºé”™è¯¯

**é”™è¯¯æ¢å¤:**
- ä»»åŠ¡é˜Ÿåˆ—æ”¯æŒé‡è¯•æœºåˆ¶
- æ–‡ä»¶ä¸Šä¼ å¤±è´¥æ—¶æ¸…ç†ä¸´æ—¶æ•°æ®
- è§£æå¤±è´¥æ—¶ä¿ç•™åŸå§‹æ–‡ä»¶ä¾¿äºé‡è¯•

**ç›‘æ§å‘Šè­¦:**
- è¯¦ç»†çš„æ—¥å¿—è®°å½•ä¾¿äºé—®é¢˜æ’æŸ¥
- è¿›åº¦çŠ¶æ€å®æ—¶æ›´æ–°åˆ°å‰ç«¯
- é”™è¯¯ä¿¡æ¯åˆ†ç±»å¤„ç†å’Œç”¨æˆ·å‹å¥½æç¤º





# å¼€å‘æŒ‡å—

## ä»£ç æœç´¢è§„åˆ™
åˆ†æä»£ç æ—¶ï¼Œè¿›è¡Œæ£€ç´¢æ—¶å¿…é¡»å¿½ç•¥ä»¥ä¸‹ç›®å½•ï¼š
- `.github` - GitHubå·¥ä½œæµé…ç½®
- `.idea` - IDEé…ç½®æ–‡ä»¶
- `.venv` - è™šæ‹Ÿç¯å¢ƒç›®å½•
- `web/node_modules` - å‰ç«¯ä¾èµ–åŒ…

## é¡¹ç›®å¯åŠ¨å‘½ä»¤

### WebæœåŠ¡å™¨å¯åŠ¨
```bash
export NLTK_DATA="/home/mydev/projects/ragflow/nltk_data"
PYTHONPATH=. poetry run python api/ragflow_server.py
```

### ä»»åŠ¡æ‰§è¡Œå™¨å¯åŠ¨
```bash
export NLTK_DATA="/home/mydev/projects/ragflow/nltk_data"
PYTHONPATH=. poetry run python rag/svr/task_executor.py
```

## æ—¥å¿—ç®¡ç†
- **ä¸»æ—¥å¿—è·¯å¾„**: `logs/ragflow_server.log`
- **ä»»åŠ¡æ‰§è¡Œå™¨æ—¥å¿—**: `logs/task_executor_0.log`
- **æ—¥å¿—æœç´¢**: éœ€è¦ä»æœ«å°¾å¾€å‰æœç´¢
- **æ—¥å¿—è½®è½¬**: è‡ªåŠ¨è½®è½¬ï¼Œä¿ç•™å†å²æ—¥å¿—

## è°ƒè¯•å’Œå¼€å‘
- **è°ƒè¯•ç«¯å£**: æ”¯æŒdebugpyè¿œç¨‹è°ƒè¯•
- **çƒ­é‡è½½**: Debugæ¨¡å¼ä¸‹æ”¯æŒä»£ç çƒ­é‡è½½
- **æ€§èƒ½ç›‘æ§**: å†…ç½®tracemallocå†…å­˜ç›‘æ§
- **APIæ–‡æ¡£**: è®¿é—® `/apidocs/` æŸ¥çœ‹Swaggeræ–‡æ¡£

## é‡è¦è¯´æ˜

æœ¬æ–‡æ¡£åŸºäºå¯¹RAGFlowé¡¹ç›®æºä»£ç çš„æ·±åº¦åˆ†æç”Ÿæˆï¼Œæ¶µç›–äº†é¡¹ç›®çš„æ ¸å¿ƒæ¶æ„ã€æŠ€æœ¯æ ˆã€æ¨¡å—åŠŸèƒ½å’Œå¼€å‘æŒ‡å—ã€‚RAGFlowæ˜¯ä¸€ä¸ªå¤æ‚çš„ä¼ä¸šçº§RAGç³»ç»Ÿï¼Œå…·å¤‡å®Œæ•´çš„æ–‡æ¡£å¤„ç†ã€çŸ¥è¯†ç®¡ç†ã€AIå¯¹è¯ç­‰åŠŸèƒ½æ¨¡å—ã€‚

## å­¦ä¹ èµ„æº

é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„`ragflowå­¦ä¹ èµ„æ–™/`æ–‡ä»¶å¤¹åŒ…å«äº†è¯¦ç»†çš„å­¦ä¹ æ–‡æ¡£ï¼š
- `RAGFlow-DialogServiceä»£ç åˆ†ææ–‡æ¡£.md` - å¯¹è¯æœåŠ¡è¯¦ç»†åˆ†æ
- `ragflow-è¡¨ç»“æ„åˆ†æ-å¤§æ¨¡å‹.md` - æ•°æ®åº“è®¾è®¡åˆ†æ
- `å¯¹è¯æµç¨‹ä»£ç æ³¨é‡Š.md` - å¯¹è¯æµç¨‹è¯¦è§£

è¿™äº›èµ„æ–™æœ‰åŠ©äºæ·±å…¥ç†è§£RAGFlowçš„å†…éƒ¨å·¥ä½œæœºåˆ¶å’Œè®¾è®¡æ€è·¯ã€‚

## 15. æ–‡ä»¶å­˜å‚¨æ¶æ„

### 15.1 å­˜å‚¨ç³»ç»Ÿæ¦‚è¿°

RAGFlowé‡‡ç”¨å¯æ’æ‹”çš„å­˜å‚¨æ¶æ„ï¼Œæ”¯æŒå¤šç§å­˜å‚¨åç«¯ï¼Œé€šè¿‡å·¥å‚æ¨¡å¼å®ç°å­˜å‚¨å±‚çš„æŠ½è±¡å’Œåˆ‡æ¢ã€‚å­˜å‚¨ç³»ç»Ÿä¸»è¦è´Ÿè´£åŸå§‹æ–‡æ¡£æ–‡ä»¶ã€æ–‡æ¡£ç¼©ç•¥å›¾ã€è§£æåçš„å›¾ç‰‡ç­‰äºŒè¿›åˆ¶æ•°æ®çš„ç®¡ç†ã€‚

### 15.2 å­˜å‚¨ç±»å‹æ”¯æŒ

| å­˜å‚¨ç±»å‹ | é…ç½®æ ‡è¯† | å®ç°ç±» | ç‰¹ç‚¹è¯´æ˜ |
|----------|----------|--------|----------|
| MinIO | `MINIO` | `RAGFlowMinio` | é»˜è®¤æ¨èï¼Œå…¼å®¹S3 API |
| æœ¬åœ°å­˜å‚¨ | `LOCAL` | `LocalFileStorage` | ç®€å•éƒ¨ç½²ï¼Œå•æœºä½¿ç”¨ |
| AWS S3 | `AWS_S3` | `RAGFlowS3` | äº‘åŸç”Ÿï¼Œé«˜å¯ç”¨ |
| é˜¿é‡Œäº‘OSS | `OSS` | `RAGFlowOSS` | å›½å†…äº‘æœåŠ¡ |
| Azure Blob | `AZURE_SPN/AZURE_SAS` | `RAGFlowAzureSpnBlob` | å¾®è½¯äº‘æœåŠ¡ |
| OpenDAL | `OPENDAL` | `OpenDALStorage` | ç»Ÿä¸€æ•°æ®è®¿é—®å±‚ |

### 15.3 é…ç½®å’Œåˆå§‹åŒ–

#### 15.3.1 é…ç½®æ–‡ä»¶ (`conf/service_conf.yaml`)
```yaml
# å­˜å‚¨å®ç°é€‰æ‹©: 'LOCAL', 'MINIO', 'OSS', 'AZURE_SPN', 'AZURE_SAS','AWS_S3'
storage_impl: 'minio'

# æœ¬åœ°å­˜å‚¨è·¯å¾„é…ç½®
local_storage_path: './datafiles'

# MinIOé…ç½® (é»˜è®¤ä½¿ç”¨)
minio:
  user: 'minioadmin'
  password: 'minioadmin'
  host: '172.20.208.1:9001'
```

#### 15.3.2 å­˜å‚¨é…ç½®åŠ è½½ (`rag/settings.py:25-58`)
```python
# ä»é…ç½®æ–‡ä»¶åŠ è½½å­˜å‚¨ç±»å‹
STORAGE_IMPL_TYPE = get_base_config("storage_impl", "MINIO").upper()

# æ ¹æ®å­˜å‚¨ç±»å‹åˆå§‹åŒ–ç›¸åº”é…ç½®
if STORAGE_IMPL_TYPE == 'LOCAL':
    LOCAL_STORAGE_PATH = get_base_config.get("local_storage_path",
                                             os.path.join(get_project_base_directory(), "datafiles"))
elif STORAGE_IMPL_TYPE == 'MINIO':
    MINIO = decrypt_database_config(name="minio")
elif STORAGE_IMPL_TYPE == 'AWS_S3':
    S3 = get_base_config("s3", {})
# ... å…¶ä»–å­˜å‚¨ç±»å‹é…ç½®
```

#### 15.3.3 å­˜å‚¨å·¥å‚æ¨¡å¼ (`rag/utils/storage_factory.py`)
```python
class Storage(Enum):
    MINIO = 1
    AZURE_SPN = 2
    AZURE_SAS = 3
    AWS_S3 = 4
    OSS = 5
    OPENDAL = 6
    LOCAL = 7

class StorageFactory:
    storage_mapping = {
        Storage.MINIO: RAGFlowMinio,
        Storage.AZURE_SPN: RAGFlowAzureSpnBlob,
        Storage.AZURE_SAS: RAGFlowAzureSasBlob,
        Storage.AWS_S3: RAGFlowS3,
        Storage.OSS: RAGFlowOSS,
        Storage.OPENDAL: OpenDALStorage,
        Storage.LOCAL: LocalFileStorage
    }

    @classmethod
    def create(cls, storage: Storage):
        return cls.storage_mapping[storage]()

# å…¨å±€å­˜å‚¨å®ä¾‹ - å•ä¾‹æ¨¡å¼
STORAGE_IMPL = StorageFactory.create(Storage[STORAGE_IMPL_TYPE])
```

### 15.4 MinIOå­˜å‚¨å®ç°åˆ†æ

#### 15.4.1 æ ¸å¿ƒç‰¹æ€§ (`rag/utils/minio_conn.py`)
- **å•ä¾‹æ¨¡å¼**: `@singleton`è£…é¥°å™¨ç¡®ä¿å…¨å±€å”¯ä¸€å®ä¾‹
- **è¿æ¥ç®¡ç†**: è‡ªåŠ¨é‡è¿æœºåˆ¶å’Œè¿æ¥æ± 
- **é‡è¯•æœºåˆ¶**: å…³é”®æ“ä½œæ”¯æŒå¤šæ¬¡é‡è¯•
- **æ¡¶ç®¡ç†**: è‡ªåŠ¨åˆ›å»ºæ¡¶ï¼Œæ”¯æŒæ¡¶åˆ é™¤

#### 15.4.2 å…³é”®æ–¹æ³•å®ç°
```python
@singleton
class RAGFlowMinio:
    def put(self, bucket, fnm, binary):
        for _ in range(3):  # é‡è¯•3æ¬¡
            try:
                if not self.conn.bucket_exists(bucket):
                    self.conn.make_bucket(bucket)  # è‡ªåŠ¨åˆ›å»ºæ¡¶
                
                r = self.conn.put_object(bucket, fnm,
                                       BytesIO(binary), len(binary))
                return r
            except Exception:
                logging.exception(f"Fail to put {bucket}/{fnm}:")
                self.__open__()  # é‡æ–°è¿æ¥
                time.sleep(1)
    
    def get(self, bucket, filename):
        for _ in range(1):  # ä»…é‡è¯•1æ¬¡
            try:
                r = self.conn.get_object(bucket, filename)
                return r.read()
            except Exception:
                logging.exception(f"Fail to get {bucket}/{filename}")
                self.__open__()
                time.sleep(1)
        return
    
    def obj_exist(self, bucket, filename):
        try:
            if not self.conn.bucket_exists(bucket):
                return False
            if self.conn.stat_object(bucket, filename):
                return True
            return False
        except S3Error as e:
            if e.code in ["NoSuchKey", "NoSuchBucket", "ResourceNotFound"]:
                return False
        except Exception:
            logging.exception(f"obj_exist {bucket}/{filename} got exception")
            return False
```

### 15.5 æœ¬åœ°å­˜å‚¨å®ç°åˆ†æ

#### 15.5.1 å®ç°ç‰¹ç‚¹ (`rag/utils/local_storage.py`)
- **ç®€åŒ–è®¾è®¡**: åŸºäºæ ‡å‡†æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
- **ç›®å½•ç»“æ„**: `base_path/bucket/filename`çš„å±‚æ¬¡ç»“æ„
- **è‡ªåŠ¨åˆ›å»º**: è‡ªåŠ¨åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
- **å•ä¾‹æ¨¡å¼**: ç¡®ä¿é…ç½®ä¸€è‡´æ€§

#### 15.5.2 æ ¸å¿ƒæ–¹æ³•å®ç°
```python
@singleton
class LocalFileStorage:
    def __init__(self):
        self.base_path = settings.LOCAL_STORAGE_PATH
        os.makedirs(self.base_path, exist_ok=True)
    
    def _path(self, bucket, fnm):
        bucket_dir = os.path.join(self.base_path, bucket)
        os.makedirs(bucket_dir, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºç›®å½•
        return os.path.join(bucket_dir, fnm)
    
    def put(self, bucket, fnm, binary):
        path = self._path(bucket, fnm)
        with open(path, 'wb') as f:
            f.write(binary)
        return True
    
    def get(self, bucket, fnm):
        with open(self._path(bucket, fnm), 'rb') as f:
            return f.read()
    
    def obj_exist(self, bucket, fnm):
        return os.path.exists(self._path(bucket, fnm))
```

### 15.6 æœ¬åœ°å­˜å‚¨æ½œåœ¨Bugåˆ†æ

#### 15.6.1 å·²è¯†åˆ«çš„Bug

1. **è®¾ç½®åŠ è½½Bug** (`rag/settings.py:57`)
   ```python
   # é”™è¯¯: get_base_configä¸æ˜¯å­—å…¸ï¼Œä¸èƒ½ä½¿ç”¨.get()æ–¹æ³•
   LOCAL_STORAGE_PATH = get_base_config.get("local_storage_path",
                                            os.path.join(get_project_base_directory(), "datafiles"))
   
   # åº”è¯¥ä¿®å¤ä¸º:
   LOCAL_STORAGE_PATH = get_base_config("local_storage_path",
                                        os.path.join(get_project_base_directory(), "datafiles"))
   ```

2. **æ–‡ä»¶è¯»å–å¼‚å¸¸å¤„ç†ç¼ºå¤±** (`local_storage.py:29-31`)
   ```python
   # å½“å‰å®ç°: æ²¡æœ‰å¼‚å¸¸å¤„ç†
   def get(self, bucket, fnm):
       with open(self._path(bucket, fnm), 'rb') as f:
           return f.read()
   
   # å»ºè®®ä¿®å¤:
   def get(self, bucket, fnm):
       try:
           with open(self._path(bucket, fnm), 'rb') as f:
               return f.read()
       except FileNotFoundError:
           logging.warning("File not found: %s/%s", bucket, fnm)
           return None
       except Exception as e:
           logging.exception("Failed to read file %s/%s: %s", bucket, fnm, e)
           raise
   ```

3. **å¥åº·æ£€æŸ¥é—ç•™æ–‡ä»¶** (`local_storage.py:36-45`)
   ```python
   # æ½œåœ¨é—®é¢˜: å¦‚æœåˆ é™¤å¤±è´¥ï¼Œä¼šé—ç•™æµ‹è¯•æ–‡ä»¶
   def health(self):
       try:
           test_path = self._path("health", "check")
           with open(test_path, "wb") as f:
               f.write(b"ok")
           os.remove(test_path)  # å¦‚æœè¿™é‡Œå¤±è´¥ï¼Œæ–‡ä»¶ä¼šæ®‹ç•™
           return True
       except Exception as e:
           logging.exception("Local storage health check failed: %s", e)
           return False
   
   # å»ºè®®ä¿®å¤:
   def health(self):
       test_path = None
       try:
           test_path = self._path("health", "check")
           with open(test_path, "wb") as f:
               f.write(b"ok")
           return True
       except Exception as e:
           logging.exception("Local storage health check failed: %s", e)
           return False
       finally:
           if test_path and os.path.exists(test_path):
               try:
                   os.remove(test_path)
               except Exception:
                   logging.warning("Failed to cleanup health check file: %s", test_path)
   ```

#### 15.6.2 å…¼å®¹æ€§é—®é¢˜

1. **è·¯å¾„åˆ†éš”ç¬¦**: åœ¨Windowsç¯å¢ƒä¸‹å¯èƒ½å­˜åœ¨è·¯å¾„åˆ†éš”ç¬¦é—®é¢˜
2. **æ–‡ä»¶æƒé™**: åœ¨æŸäº›Unixç³»ç»Ÿä¸Šå¯èƒ½å­˜åœ¨æƒé™é—®é¢˜
3. **å¹¶å‘è®¿é—®**: å¤šè¿›ç¨‹åŒæ—¶å†™å…¥ç›¸åŒæ–‡ä»¶æ—¶ç¼ºä¹é”ä¿æŠ¤

#### 15.6.3 æ€§èƒ½é—®é¢˜

1. **ç¼ºä¹ç¼“å­˜**: é¢‘ç¹çš„æ–‡ä»¶ç³»ç»Ÿæ“ä½œæ²¡æœ‰ç¼“å­˜æœºåˆ¶
2. **å¤§æ–‡ä»¶å¤„ç†**: ä¸€æ¬¡æ€§è¯»å–æ•´ä¸ªæ–‡ä»¶åˆ°å†…å­˜ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º
3. **ç›®å½•éå†**: æ²¡æœ‰å®ç°åˆ—è¡¨åŠŸèƒ½ï¼Œæ— æ³•éå†å­˜å‚¨å†…å®¹

### 15.7 å­˜å‚¨ä½¿ç”¨åœºæ™¯

#### 15.7.1 å…¨å±€ä½¿ç”¨ä½ç½®
é€šè¿‡æœç´¢`STORAGE_IMPL`åœ¨ä»£ç ä¸­çš„ä½¿ç”¨ï¼Œå‘ç°ä»¥ä¸‹å…³é”®ä½ç½®ï¼š

1. **æ–‡æ¡£ä¸Šä¼ ** (`api/apps/document_app.py:upload()`)
   ```python
   # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
   while STORAGE_IMPL.obj_exist(kb_id, location):
       location += "_"
   # ä¸Šä¼ æ–‡ä»¶åˆ°å­˜å‚¨
   STORAGE_IMPL.put(kb_id, location, blob)
   ```

2. **æ–‡æ¡£ä¸‹è½½** (`api/apps/document_app.py:get()`)
   ```python
   # ä»å­˜å‚¨è·å–æ–‡ä»¶
   binary = STORAGE_IMPL.get(bucket, name)
   ```

3. **æ–‡æ¡£åˆ é™¤** (`api/db/services/document_service.py:remove_document()`)
   ```python
   # åˆ é™¤å…³è”å›¾ç‰‡å’Œç¼©ç•¥å›¾
   for cid in all_chunk_ids:
       if STORAGE_IMPL.obj_exist(doc.kb_id, cid):
           STORAGE_IMPL.rm(doc.kb_id, cid)
   ```

4. **ä»»åŠ¡æ‰§è¡Œå™¨** (`rag/svr/task_executor.py:get_storage_binary()`)
   ```python
   # è·å–å¾…å¤„ç†æ–‡ä»¶
   async def get_storage_binary(bucket, name):
       return await trio.to_thread.run_sync(
           lambda: STORAGE_IMPL.get(bucket, name)
       )
   ```

#### 15.7.2 å­˜å‚¨å±‚æ¬¡ç»“æ„

**æ¡¶(Bucket)å‘½åè§„åˆ™:**
- **çŸ¥è¯†åº“ID**: æ–‡æ¡£å’Œå›¾ç‰‡æŒ‰çŸ¥è¯†åº“IDåˆ†æ¡¶å­˜å‚¨
- **ç§Ÿæˆ·éš”ç¦»**: é€šè¿‡æ¡¶åå®ç°ç§Ÿæˆ·æ•°æ®éš”ç¦»
- **ç±»å‹åˆ†ç±»**: ä¸åŒç±»å‹æ–‡ä»¶å¯èƒ½ä½¿ç”¨ä¸åŒæ¡¶

**æ–‡ä»¶å‘½åè§„åˆ™:**
- **æ–‡æ¡£æ–‡ä»¶**: ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œå†²çªæ—¶æ·»åŠ ä¸‹åˆ’çº¿
- **å›¾ç‰‡æ–‡ä»¶**: ä½¿ç”¨chunk_idä½œä¸ºæ–‡ä»¶å
- **ç¼©ç•¥å›¾**: åŸºäºæ–‡ä»¶å†…å®¹ç”Ÿæˆå”¯ä¸€æ ‡è¯†

### 15.8 å­˜å‚¨è·¯å¾„ä¿å­˜æœºåˆ¶

#### 15.8.1 å­˜å‚¨è·¯å¾„æ„æˆè§„åˆ™

**ç‰©ç†å­˜å‚¨è·¯å¾„æ„æˆ**:
```
å­˜å‚¨åç«¯:
  â”œâ”€â”€ bucket (çŸ¥è¯†åº“ID)
  â”‚   â”œâ”€â”€ filename (åŸå§‹æ–‡ä»¶å)
  â”‚   â”œâ”€â”€ filename_ (é‡åå†²çªå¤„ç†)
  â”‚   â”œâ”€â”€ thumbnail_doc_id.png (ç¼©ç•¥å›¾)
  â”‚   â””â”€â”€ chunk_id (æ–‡æ¡£å—å…³è”å›¾ç‰‡)
```

**è·¯å¾„ç”Ÿæˆé€»è¾‘** (`api/db/services/file_service.py:423-430`):
```python
# 1. åˆå§‹locationä¸ºåŸå§‹æ–‡ä»¶å
location = filename

# 2. æ£€æŸ¥é‡åå†²çªï¼Œæ·»åŠ ä¸‹åˆ’çº¿åç¼€
while STORAGE_IMPL.obj_exist(kb.id, location):
    location += "_"

# 3. å®é™…å­˜å‚¨ï¼šä½¿ç”¨kb_idä½œä¸ºbucketï¼Œlocationä½œä¸ºæ–‡ä»¶å
STORAGE_IMPL.put(kb.id, location, blob)

# 4. ç¼©ç•¥å›¾å­˜å‚¨
thumbnail_location = f"thumbnail_{doc_id}.png"
STORAGE_IMPL.put(kb.id, thumbnail_location, img)
```

#### 15.8.2 æ•°æ®åº“å­˜å‚¨è·¯å¾„è®°å½•

**Documentè¡¨è·¯å¾„ä¿¡æ¯** (`api/db/db_models.py:615-640`):
| å­—æ®µ | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|------|------|------|-------|
| `id` | CharField(32) | æ–‡æ¡£å”¯ä¸€æ ‡è¯† | "abc123..." |
| `kb_id` | CharField(256) | çŸ¥è¯†åº“ID(å­˜å‚¨æ¡¶å) | "kb_001" |
| `location` | CharField(255) | å­˜å‚¨æ–‡ä»¶å | "document.pdf" æˆ– "document.pdf_" |
| `thumbnail` | TextField | ç¼©ç•¥å›¾è·¯å¾„ | "thumbnail_abc123.png" |
| `name` | CharField(255) | æ˜¾ç¤ºæ–‡ä»¶å | "æˆ‘çš„æ–‡æ¡£.pdf" |

**Fileè¡¨è·¯å¾„ä¿¡æ¯** (`api/db/db_models.py:642-654`):
| å­—æ®µ | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|------|------|------|-------|
| `id` | CharField(32) | æ–‡ä»¶å”¯ä¸€æ ‡è¯† | "file123..." |
| `location` | CharField(255) | å­˜å‚¨ä½ç½®(ä¸Documentç›¸åŒ) | "document.pdf" |
| `parent_id` | CharField(32) | çˆ¶æ–‡ä»¶å¤¹ID | "folder001" |
| `tenant_id` | CharField(32) | ç§Ÿæˆ·ID | "tenant001" |

**File2Documentå…³è”è¡¨** (`api/db/db_models.py:657-663`):
| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `file_id` | CharField(32) | æ–‡ä»¶ID |
| `document_id` | CharField(32) | æ–‡æ¡£ID |

#### 15.8.3 å­˜å‚¨åœ°å€è·å–æœºåˆ¶

**æ ¸å¿ƒæ–¹æ³•** (`api/db/services/file2document_service.py:68-81`):
```python
def get_storage_address(cls, doc_id=None, file_id=None):
    """è·å–æ–‡ä»¶çš„å­˜å‚¨åœ°å€
    
    Returns:
        tuple: (bucket, location) - (æ¡¶å, æ–‡ä»¶å)
    """
    if doc_id:
        # é€šè¿‡document_idæŸ¥æ‰¾å…³è”çš„file
        f2d = cls.get_by_document_id(doc_id)
    else:
        # é€šè¿‡file_idæŸ¥æ‰¾å…³è”çš„document
        f2d = cls.get_by_file_id(file_id)
    
    if f2d:
        file = File.get_by_id(f2d[0].file_id)
        # æœ¬åœ°æ–‡ä»¶ç±»å‹ä½¿ç”¨ä¸åŒçš„å­˜å‚¨ç­–ç•¥
        if not file.source_type or file.source_type == FileSource.LOCAL:
            return file.parent_id, file.location
        doc_id = f2d[0].document_id

    # çŸ¥è¯†åº“æ–‡ä»¶ä½¿ç”¨documentçš„å­˜å‚¨ä¿¡æ¯
    e, doc = DocumentService.get_by_id(doc_id)
    return doc.kb_id, doc.location  # (bucket, filename)
```

#### 15.8.4 æ–‡ä»¶ä¸Šä¼ å­˜å‚¨æµç¨‹è¯¦è§£

**å®Œæ•´çš„æ–‡ä»¶ä¸Šä¼ å’Œè·¯å¾„ä¿å­˜æµç¨‹**:

1. **æ–‡ä»¶ä¸Šä¼ æ¥å£** (`api/apps/document_app.py:53-77`):
   ```python
   # æ¥æ”¶ä¸Šä¼ æ–‡ä»¶ï¼Œè°ƒç”¨FileService.upload_document
   err, files = FileService.upload_document(kb, file_objs, current_user.id)
   ```

2. **æ–‡æ¡£è®°å½•åˆ›å»º** (`api/db/services/file_service.py:440-452`):
   ```python
   doc = {
       "id": doc_id,                    # æ–‡æ¡£UUID
       "kb_id": kb.id,                  # çŸ¥è¯†åº“ID (å­˜å‚¨æ¡¶å)
       "location": location,            # å­˜å‚¨æ–‡ä»¶å (å¤„ç†é‡åå)
       "name": filename,                # åŸå§‹æ–‡ä»¶å
       "thumbnail": thumbnail_location, # ç¼©ç•¥å›¾è·¯å¾„
       "size": len(blob),              # æ–‡ä»¶å¤§å°
       # ... å…¶ä»–å­—æ®µ
   }
   DocumentService.insert(doc)
   ```

3. **æ–‡ä»¶è®°å½•åˆ›å»º** (`api/db/services/file_service.py:377-389`):
   ```python
   file = {
       "id": get_uuid(),               # æ–‡ä»¶UUID
       "parent_id": kb_folder_id,      # çŸ¥è¯†åº“æ–‡ä»¶å¤¹ID
       "tenant_id": tenant_id,         # ç§Ÿæˆ·ID
       "name": doc["name"],            # æ–‡ä»¶å
       "location": doc["location"],    # å­˜å‚¨ä½ç½®(ä¸documentç›¸åŒ)
       "type": doc["type"],            # æ–‡ä»¶ç±»å‹
       "size": doc["size"],            # æ–‡ä»¶å¤§å°
   }
   FileService.save(**file)
   ```

4. **å…³è”å…³ç³»åˆ›å»º** (`api/db/services/file_service.py:389`):
   ```python
   File2DocumentService.save(**{
       "id": get_uuid(),
       "file_id": file["id"],
       "document_id": doc["id"]
   })
   ```

#### 15.8.5 å®é™…å­˜å‚¨ç¤ºä¾‹

**ç¤ºä¾‹åœºæ™¯**: ç”¨æˆ·ä¸Šä¼ "æŠ€æœ¯æ–‡æ¡£.pdf"åˆ°çŸ¥è¯†åº“"kb_tech_001"

**å­˜å‚¨è·¯å¾„æ„æˆ**:
```
MinIO/æœ¬åœ°å­˜å‚¨:
â””â”€â”€ kb_tech_001/                    # æ¡¶å = çŸ¥è¯†åº“ID
    â”œâ”€â”€ æŠ€æœ¯æ–‡æ¡£.pdf                 # åŸå§‹æ–‡ä»¶ (location)
    â”œâ”€â”€ thumbnail_abc123.png         # ç¼©ç•¥å›¾
    â””â”€â”€ chunk_def456/                # æ–‡æ¡£å—å…³è”å›¾ç‰‡
        â”œâ”€â”€ image_001.jpg
        â””â”€â”€ image_002.jpg
```

**æ•°æ®åº“è®°å½•**:
```sql
-- documentè¡¨
INSERT INTO document (
    id = 'abc123-def456-789',
    kb_id = 'kb_tech_001',           -- å­˜å‚¨æ¡¶å
    location = 'æŠ€æœ¯æ–‡æ¡£.pdf',        -- å­˜å‚¨æ–‡ä»¶å
    name = 'æŠ€æœ¯æ–‡æ¡£.pdf',            -- æ˜¾ç¤ºæ–‡ä»¶å
    thumbnail = 'thumbnail_abc123.png' -- ç¼©ç•¥å›¾è·¯å¾„
);

-- fileè¡¨  
INSERT INTO file (
    id = 'file789-abc123-def',
    parent_id = 'folder_kb_tech',     -- çŸ¥è¯†åº“æ–‡ä»¶å¤¹ID
    tenant_id = 'tenant_001',         -- ç§Ÿæˆ·ID
    location = 'æŠ€æœ¯æ–‡æ¡£.pdf',        -- ä¸document.locationç›¸åŒ
    name = 'æŠ€æœ¯æ–‡æ¡£.pdf'
);

-- file2documentå…³è”è¡¨
INSERT INTO file2document (
    file_id = 'file789-abc123-def',
    document_id = 'abc123-def456-789'
);
```

**è·å–å­˜å‚¨åœ°å€**:
```python
# é€šè¿‡document_idè·å–å­˜å‚¨åœ°å€
bucket, location = File2DocumentService.get_storage_address(doc_id='abc123-def456-789')
# è¿”å›: ('kb_tech_001', 'æŠ€æœ¯æ–‡æ¡£.pdf')

# å®é™…æ–‡ä»¶è®¿é—®
binary = STORAGE_IMPL.get(bucket, location)
```

#### 15.8.6 ç‰¹æ®Šæ–‡ä»¶ç±»å‹å¤„ç†

**ç¼©ç•¥å›¾æ–‡ä»¶**:
- è·¯å¾„æ¨¡å¼: `thumbnail_{doc_id}.png`
- å­˜å‚¨ä½ç½®: ä¸åŸæ–‡ä»¶ç›¸åŒæ¡¶
- æ•°æ®åº“å­—æ®µ: `document.thumbnail`

**æ–‡æ¡£å—å…³è”å›¾ç‰‡**:
- è·¯å¾„æ¨¡å¼: ä½¿ç”¨`chunk_id`ä½œä¸ºæ–‡ä»¶å
- å­˜å‚¨ä½ç½®: ä¸åŸæ–‡ä»¶ç›¸åŒæ¡¶
- è·å–æ–¹å¼: é€šè¿‡å‘é‡æ•°æ®åº“æŸ¥è¯¢chunkä¸­çš„`img_id`å­—æ®µ

**é‡åå†²çªå¤„ç†**:
- æ£€æµ‹æœºåˆ¶: `duplicate_name()`å‡½æ•°æ£€æŸ¥æ•°æ®åº“é‡å
- å¤„ç†ç­–ç•¥: åœ¨æ–‡ä»¶ååæ·»åŠ æ•°å­—åç¼€ `filename(1)`, `filename(2)`
- ä¿è¯å”¯ä¸€æ€§: ç¡®ä¿åŒä¸€çŸ¥è¯†åº“ä¸‹æ–‡æ¡£åå”¯ä¸€

### 15.9 æ–‡ä»¶é‡å‘½åæœºåˆ¶è¯¦è§£

#### 15.9.1 é‡å‘½åæœºåˆ¶æ¦‚è¿°

RAGFlowçš„æ–‡ä»¶ä¸Šä¼ é‡‡ç”¨**ä¸¤å±‚é‡å‘½åæœºåˆ¶**ï¼Œç¡®ä¿æ–‡ä»¶ä¸ä¼šè¢«è¦†ç›–ï¼š

1. **æ•°æ®åº“å±‚é‡å‘½å**ï¼šé¿å…æ•°æ®åº“è®°å½•å†²çª
2. **å­˜å‚¨å±‚é‡å‘½å**ï¼šé¿å…ç‰©ç†æ–‡ä»¶å†²çªï¼ˆæå°‘è§¦å‘ï¼‰

#### 15.9.2 æ•°æ®åº“å±‚é‡å‘½åï¼ˆä¸»è¦æœºåˆ¶ï¼‰

**å®ç°ä½ç½®**ï¼š`api/db/services/file_service.py:418`
```python
filename = duplicate_name(DocumentService.query, name=file.filename, kb_id=kb.id)
```

**æ ¸å¿ƒå‡½æ•°**ï¼š`api/db/services/__init__.py:45-99` - `duplicate_name()`

**é‡å‘½åè§„åˆ™**ï¼š
```python
def duplicate_name(query_func, **kwargs) -> str:
    """
    ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼Œé€šè¿‡æ·»åŠ /é€’å¢è®¡æ•°å™¨å¤„ç†é‡å
    
    é‡å‘½åæ ¼å¼ï¼š
    - åŸå§‹æ–‡ä»¶: document.pdf
    - ç¬¬1æ¬¡é‡å: document(1).pdf  
    - ç¬¬2æ¬¡é‡å: document(2).pdf
    - ç¬¬3æ¬¡é‡å: document(3).pdf
    """
    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨åŒåè®°å½•
    # å¦‚æœå­˜åœ¨ï¼Œåœ¨æ–‡ä»¶åsteméƒ¨åˆ†æ·»åŠ (1)ã€(2)ç­‰åç¼€
    # æœ€å¤šå°è¯•1000æ¬¡ï¼Œç¡®ä¿æ‰¾åˆ°å”¯ä¸€åç§°
```

**å®é™…æµ‹è¯•ç»“æœ**ï¼š
| ä¸Šä¼ é¡ºåº | åŸå§‹æ–‡ä»¶å | æ•°æ®åº“ä¿å­˜åç§° | ç‰©ç†å­˜å‚¨åç§° |
|----------|------------|----------------|-------------|
| ç¬¬1æ¬¡ | A.md | A.md | A.md |
| ç¬¬2æ¬¡ | A.md | A(1).md | A(1).md |
| ç¬¬3æ¬¡ | A.md | A(2).md | A(2).md |
| ç¬¬4æ¬¡ | A.md | A(3).md | A(3).md |

#### 15.9.3 å­˜å‚¨å±‚é‡å‘½åï¼ˆç†è®ºæœºåˆ¶ï¼‰

**å®ç°ä½ç½®**ï¼š`api/db/services/file_service.py:423-425`
```python
location = filename  # ä½¿ç”¨æ•°æ®åº“å±‚å¤„ç†åçš„æ–‡ä»¶å
while STORAGE_IMPL.obj_exist(kb.id, location):
    location += "_"  # æ·»åŠ ä¸‹åˆ’çº¿åç¼€
```

**è§¦å‘æ¡ä»¶**ï¼ˆæå°‘å‘ç”Ÿï¼‰ï¼š
1. **æ–‡ä»¶ç³»ç»Ÿå¼‚å¸¸**ï¼šç›´æ¥æ‹·è´æ–‡ä»¶åˆ°å­˜å‚¨ç›®å½•ç»•è¿‡æ•°æ®åº“
2. **å¹¶å‘å†²çª**ï¼šæé«˜å¹¶å‘ä¸‹çš„ç«æ€æ¡ä»¶
3. **å­˜å‚¨æ®‹ç•™**ï¼šå¼‚å¸¸ä¸­æ–­å¯¼è‡´çš„æ–‡ä»¶æ®‹ç•™

**é‡å‘½åæ ¼å¼**ï¼š
```
document.pdf â†’ document.pdf_
document.pdf â†’ document.pdf__  
document.pdf â†’ document.pdf___
```

#### 15.9.4 å®Œæ•´çš„æ–‡ä»¶ä¸Šä¼ æµç¨‹

```python
# 1. æ•°æ®åº“å±‚é‡å‘½åæ£€æŸ¥
filename = duplicate_name(DocumentService.query, name=file.filename, kb_id=kb.id)
# ç»“æœ: A.md â†’ A(1).md (å¦‚æœé‡å)

# 2. å­˜å‚¨å±‚é‡å‘½åæ£€æŸ¥  
location = filename
while STORAGE_IMPL.obj_exist(kb.id, location):
    location += "_"
# ç»“æœ: A(1).md â†’ A(1).md (é€šå¸¸ä¸å˜)

# 3. ç‰©ç†å­˜å‚¨
STORAGE_IMPL.put(kb.id, location, blob)

# 4. æ•°æ®åº“è®°å½•
doc = {
    "name": filename,      # æ˜¾ç¤ºåç§°: A(1).md
    "location": location,  # å­˜å‚¨åç§°: A(1).md  
    "kb_id": kb.id        # å­˜å‚¨æ¡¶: çŸ¥è¯†åº“ID
}
DocumentService.insert(doc)
```

#### 15.9.5 å­˜å‚¨è·¯å¾„æ„æˆæ€»ç»“

**æœ€ç»ˆå­˜å‚¨è·¯å¾„å…¬å¼**ï¼š
```
{LOCAL_STORAGE_PATH}/{kb_id}/{å¤„ç†åçš„æ–‡ä»¶å}

å®é™…ç¤ºä¾‹ï¼š
./datafiles/kb_001/A.md      (ç¬¬1æ¬¡ä¸Šä¼ )
./datafiles/kb_001/A(1).md   (ç¬¬2æ¬¡ä¸Šä¼ )  
./datafiles/kb_001/A(2).md   (ç¬¬3æ¬¡ä¸Šä¼ )
```

**æ•°æ®åº“å­—æ®µæ˜ å°„**ï¼š
- `document.kb_id`ï¼šå­˜å‚¨æ¡¶åï¼ˆçŸ¥è¯†åº“IDï¼‰
- `document.name`ï¼šç”¨æˆ·æ˜¾ç¤ºåç§°ï¼ˆé‡å‘½ååï¼‰
- `document.location`ï¼šå®é™…å­˜å‚¨æ–‡ä»¶åï¼ˆé‡å‘½ååï¼‰
- `file.parent_id`ï¼šæ–‡ä»¶å¤¹UUIDï¼ˆç”¨äºæœ¬åœ°æ–‡ä»¶å­˜å‚¨æ—¶çš„æ¡¶åï¼‰
- `file.location`ï¼šä¸document.locationç›¸åŒ

#### 15.9.6 é‡å‘½åæœºåˆ¶çš„è®¾è®¡ä¼˜åŠ¿

1. **æ•°æ®ä¸€è‡´æ€§**ï¼šæ•°æ®åº“è®°å½•ä¸ç‰©ç†å­˜å‚¨å®Œå…¨å¯¹åº”
2. **ç”¨æˆ·å‹å¥½**ï¼šè‡ªåŠ¨å¤„ç†é‡åï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨é‡å‘½å
3. **ç³»ç»Ÿå¥å£®**ï¼šåŒé‡æ£€æŸ¥æœºåˆ¶ï¼Œé¿å…ä»»ä½•å½¢å¼çš„æ–‡ä»¶è¦†ç›–
4. **å¯è¿½æº¯æ€§**ï¼šä¿ç•™åŸå§‹æ–‡ä»¶åè¯­ä¹‰ï¼Œä¾¿äºç”¨æˆ·è¯†åˆ«
5. **æ‰©å±•æ€§**ï¼šæ”¯æŒæœ€å¤š1000ä¸ªåŒåæ–‡ä»¶ï¼Œæ»¡è¶³å®é™…éœ€æ±‚

#### 15.9.7 ç‰¹æ®Šæƒ…å†µå¤„ç†

**æ–‡ä»¶åè§£æè§„åˆ™**ï¼š
```python
def split_name_counter(filename: str) -> tuple[str, int | None]:
    """
    è§£ææ–‡ä»¶åä¸­çš„è®¡æ•°å™¨
    
    ç¤ºä¾‹ï¼š
    "document.pdf" â†’ ("document.pdf", None)
    "document(1).pdf" â†’ ("document", 1)  
    "document(5).pdf" â†’ ("document", 5)
    """
    pattern = re.compile(r"^(.*?)\((\d+)\)$")
    # åŒ¹é… "ä¸»æ–‡ä»¶å(æ•°å­—)" æ¨¡å¼
```

**è¾¹ç•Œæƒ…å†µ**ï¼š
- æ–‡ä»¶åå·²åŒ…å«æ‹¬å·ï¼šå¦‚`test(old).pdf` â†’ `test(old)(1).pdf`
- è¶…é•¿æ–‡ä»¶åï¼šå—æ•°æ®åº“å­—æ®µé•¿åº¦é™åˆ¶ï¼ˆ255å­—ç¬¦ï¼‰
- ç‰¹æ®Šå­—ç¬¦ï¼šä¿æŒåŸæœ‰å­—ç¬¦ï¼Œä»…åœ¨steméƒ¨åˆ†æ·»åŠ è®¡æ•°å™¨

### 15.10 å­˜å‚¨ç›‘æ§å’Œç»´æŠ¤

#### 15.10.1 å¥åº·æ£€æŸ¥
```python
# å­˜å‚¨å¥åº·æ£€æŸ¥æ¥å£
def storage_health():
    try:
        return STORAGE_IMPL.health()
    except Exception as e:
        logging.exception("Storage health check failed: %s", e)
        return False
```

#### 15.10.2 å­˜å‚¨ç»Ÿè®¡
- **å®¹é‡ä½¿ç”¨**: å®æ—¶ç»Ÿè®¡å„çŸ¥è¯†åº“å­˜å‚¨ä½¿ç”¨é‡
- **æ–‡ä»¶æ•°é‡**: è¿½è¸ªæ–‡æ¡£å’Œå›¾ç‰‡æ–‡ä»¶æ•°é‡
- **è®¿é—®é¢‘ç‡**: ç›‘æ§çƒ­ç‚¹æ–‡ä»¶è®¿é—®æ¨¡å¼

#### 15.10.3 æ•°æ®è¿ç§»
å½“éœ€è¦æ›´æ¢å­˜å‚¨åç«¯æ—¶ï¼Œç³»ç»Ÿæä¾›ä»¥ä¸‹è¿ç§»ç­–ç•¥ï¼š
1. **é…ç½®åˆ‡æ¢**: ä¿®æ”¹`storage_impl`é…ç½®
2. **æ•°æ®åŒæ­¥**: æ‰¹é‡è¿ç§»å·²æœ‰æ–‡ä»¶
3. **ä¸€è‡´æ€§æ£€æŸ¥**: éªŒè¯è¿ç§»å®Œæ•´æ€§
4. **å›æ»šæœºåˆ¶**: æ”¯æŒè¿ç§»å¤±è´¥å›æ»š

### 15.11 æœ€ä½³å®è·µå»ºè®®

#### 15.11.1 ç”Ÿäº§ç¯å¢ƒæ¨è
- **é¦–é€‰MinIO**: æ€§èƒ½ç¨³å®šï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œæ”¯æŒé›†ç¾¤
- **å¤‡ä»½ç­–ç•¥**: å®šæœŸå¤‡ä»½é‡è¦æ–‡æ¡£å’Œé…ç½®
- **ç›‘æ§å‘Šè­¦**: å®æ—¶ç›‘æ§å­˜å‚¨å®¹é‡å’Œæ€§èƒ½

#### 15.11.2 å¼€å‘æµ‹è¯•ç¯å¢ƒ
- **æœ¬åœ°å­˜å‚¨**: ç®€åŒ–éƒ¨ç½²ï¼Œå¿«é€Ÿå¼€å‘
- **æ³¨æ„äº‹é¡¹**: ä¿®å¤å·²çŸ¥Bugï¼Œå¢å¼ºé”™è¯¯å¤„ç†
- **å®¹é‡é™åˆ¶**: è®¾ç½®åˆç†çš„å­˜å‚¨é…é¢

#### 15.11.3 æ‰©å±•å¼€å‘
- **æ¥å£æ ‡å‡†åŒ–**: éµå¾ªç°æœ‰å­˜å‚¨æ¥å£è§„èŒƒ
- **å¼‚å¸¸å¤„ç†**: å®Œå–„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
- **æ€§èƒ½ä¼˜åŒ–**: è€ƒè™‘ç¼“å­˜å’Œå¼‚æ­¥å¤„ç†

RAGFlowçš„å­˜å‚¨æ¶æ„è®¾è®¡ä½“ç°äº†è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œçµæ´»æ€§ï¼Œé€šè¿‡æŠ½è±¡å±‚éš”ç¦»äº†å…·ä½“çš„å­˜å‚¨å®ç°ï¼Œä¸ºä¸åŒéƒ¨ç½²åœºæ™¯æä¾›äº†åˆé€‚çš„é€‰æ‹©ã€‚

## 16. å¼‚å¸¸å¤„ç†æœºåˆ¶

### 16.1 å¼‚å¸¸å¤„ç†æ¶æ„æ¦‚è¿°

RAGFlowé‡‡ç”¨åˆ†å±‚å¼‚å¸¸å¤„ç†æ¶æ„ï¼Œä»åº•å±‚æ•°æ®åº“æ“ä½œåˆ°ä¸Šå±‚APIæ¥å£ï¼Œå®ç°äº†ç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œé”™è¯¯å“åº”æœºåˆ¶ã€‚

### 16.2 å¼‚å¸¸åˆ†ç±»å’Œé”™è¯¯ç ä½“ç³»

#### 16.2.1 é”™è¯¯ç å®šä¹‰ (`api/settings.py:197-212`)
```python
class RetCode(IntEnum, CustomEnum):
    SUCCESS = 0                    # æˆåŠŸ
    NOT_EFFECTIVE = 10            # æ— æ•ˆæ“ä½œ
    EXCEPTION_ERROR = 100         # ç³»ç»Ÿå¼‚å¸¸
    ARGUMENT_ERROR = 101          # å‚æ•°é”™è¯¯
    DATA_ERROR = 102             # æ•°æ®é”™è¯¯
    OPERATING_ERROR = 103        # æ“ä½œé”™è¯¯
    CONNECTION_ERROR = 105       # è¿æ¥é”™è¯¯
    RUNNING = 106               # è¿è¡Œä¸­
    PERMISSION_ERROR = 108      # æƒé™é”™è¯¯
    AUTHENTICATION_ERROR = 109  # è®¤è¯é”™è¯¯
    UNAUTHORIZED = 401          # æœªæˆæƒ
    FORBIDDEN = 403            # ç¦æ­¢è®¿é—®
    NOT_FOUND = 404           # èµ„æºæœªæ‰¾åˆ°
    SERVER_ERROR = 500        # æœåŠ¡å™¨é”™è¯¯
```

#### 16.2.2 å¼‚å¸¸åˆ†ç±»ä½“ç³»
| å¼‚å¸¸ç±»å‹ | é”™è¯¯ç èŒƒå›´ | å¤„ç†å±‚çº§ | è¯´æ˜ |
|----------|-----------|----------|------|
| **ä¸šåŠ¡å¼‚å¸¸** | 10-99 | ä¸šåŠ¡é€»è¾‘å±‚ | å¯é¢„æœŸçš„ä¸šåŠ¡é”™è¯¯ |
| **å®¢æˆ·ç«¯å¼‚å¸¸** | 100-199 | APIå±‚ | å®¢æˆ·ç«¯è¯·æ±‚é”™è¯¯ |
| **è®¤è¯æˆæƒå¼‚å¸¸** | 401,403,404 | ä¸­é—´ä»¶å±‚ | æƒé™å’Œèµ„æºè®¿é—®é”™è¯¯ |
| **ç³»ç»Ÿå¼‚å¸¸** | 500+ | ç³»ç»Ÿå±‚ | ä¸å¯é¢„æœŸçš„ç³»ç»Ÿé”™è¯¯ |

### 16.3 å¼‚å¸¸å¤„ç†æµç¨‹

#### 16.3.1 APIå±‚å¼‚å¸¸å¤„ç†

**ç»Ÿä¸€å¼‚å¸¸å¤„ç†å‡½æ•°** (`api/utils/api_utils.py:115-127`):
```python
def server_error_response(e):
    # 1. è®°å½•å®Œæ•´å¼‚å¸¸å †æ ˆåˆ°æ—¥å¿—
    logging.exception(e)
    
    try:
        # 2. ç‰¹æ®ŠçŠ¶æ€ç å¤„ç†
        if e.code == 401:
            return get_json_result(code=401, message=repr(e))
    except BaseException:
        pass
    
    # 3. å¤šå‚æ•°å¼‚å¸¸å¤„ç†
    if len(e.args) > 1:
        return get_json_result(code=settings.RetCode.EXCEPTION_ERROR, 
                             message=repr(e.args[0]), data=e.args[1])
    
    # 4. ç‰¹å®šå¼‚å¸¸ç±»å‹è¯†åˆ«
    if repr(e).find("index_not_found_exception") >= 0:
        return get_json_result(code=settings.RetCode.EXCEPTION_ERROR, 
                             message="No chunk found, please upload file and parse it.")
    
    # 5. é€šç”¨å¼‚å¸¸å¤„ç†
    return get_json_result(code=settings.RetCode.EXCEPTION_ERROR, message=repr(e))
```

**æ„é€ é”™è¯¯å“åº”** (`api/utils/api_utils.py:272-281`):
```python
def construct_error_response(e):
    logging.exception(e)  # è®°å½•å¼‚å¸¸å †æ ˆ
    try:
        if e.code == 401:
            return construct_json_result(code=settings.RetCode.UNAUTHORIZED, message=repr(e))
    except BaseException:
        pass
    if len(e.args) > 1:
        return construct_json_result(code=settings.RetCode.EXCEPTION_ERROR, 
                                   message=repr(e.args[0]), data=e.args[1])
    return construct_json_result(code=settings.RetCode.EXCEPTION_ERROR, message=repr(e))
```

#### 16.3.2 Controllerå±‚å¼‚å¸¸å¤„ç†æ¨¡å¼

**å…¸å‹å¼‚å¸¸å¤„ç†æ¨¡å¼** (å„`*_app.py`æ–‡ä»¶):
```python
@manager.route("/upload", methods=["POST"])
@login_required
def upload():
    try:
        # ä¸šåŠ¡é€»è¾‘å¤„ç†
        # ...
        return get_json_result(data=files)
    except Exception as e:
        # ç»Ÿä¸€è°ƒç”¨å¼‚å¸¸å¤„ç†å‡½æ•°
        return server_error_response(e)
```

#### 16.3.3 Serviceå±‚å¼‚å¸¸å¤„ç†

**æ•°æ®åº“æ“ä½œå¼‚å¸¸å¤„ç†** (`api/db/services/common_service.py`):
```python
@classmethod
@DB.connection_context()
def save(cls, **kwargs):
    try:
        obj = cls.model.create(**kwargs)
        return obj
    except Exception as e:
        logging.exception(f"Database save failed: {e}")
        raise RuntimeError("Database error!")
```

**é‡è¯•æœºåˆ¶è£…é¥°å™¨** (`api/db/db_models.py:265-299`):
```python
def with_retry(max_retries=3, retry_delay=1.0):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for retry in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if retry < max_retries - 1:
                        current_delay = retry_delay * (2 ** retry)
                        logging.warning(f"{func.__name__} failed: {str(e)}, retrying ({retry+1}/{max_retries})")
                        time.sleep(current_delay)
                    else:
                        logging.error(f"{func.__name__} failed after all attempts: {str(e)}")
            raise last_exception
        return wrapper
    return decorator
```

### 16.4 å‰ç«¯å¼‚å¸¸ä¿¡æ¯å¤„ç†

#### 16.4.1 ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯

**é”™è¯¯æ¶ˆæ¯è½¬æ¢ç­–ç•¥**:
1. **éšè—æŠ€æœ¯ç»†èŠ‚**: ä¸å‘å‰ç«¯æš´éœ²å †æ ˆä¿¡æ¯å’Œä»£ç è·¯å¾„
2. **ä¸šåŠ¡åŒ–æè¿°**: å°†æŠ€æœ¯é”™è¯¯è½¬æ¢ä¸ºç”¨æˆ·å¯ç†è§£çš„æ¶ˆæ¯
3. **å¤šè¯­è¨€æ”¯æŒ**: æ ¹æ®ç”¨æˆ·è¯­è¨€è®¾ç½®è¿”å›å¯¹åº”é”™è¯¯æ¶ˆæ¯

**ç¤ºä¾‹è½¬æ¢**:
```python
# åŸå§‹å¼‚å¸¸: "KeyError: 'llm_id' at line 42 in dialog_service.py"
# å‰ç«¯æ˜¾ç¤º: "æ¨¡å‹é…ç½®é”™è¯¯ï¼Œè¯·é‡æ–°é€‰æ‹©æ¨¡å‹"

# åŸå§‹å¼‚å¸¸: "OperationalError: (2003, 'Connection refused')"  
# å‰ç«¯æ˜¾ç¤º: "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
```

#### 16.4.2 é”™è¯¯å“åº”æ ¼å¼æ ‡å‡†åŒ–

**ç»Ÿä¸€JSONå“åº”æ ¼å¼**:
```json
{
    "code": 101,
    "message": "å‚æ•°é”™è¯¯ï¼šç¼ºå°‘å¿…éœ€çš„çŸ¥è¯†åº“ID",
    "data": null
}
```

### 16.5 å¼‚å¸¸ç›‘æ§å’Œå‘Šè­¦

#### 16.5.1 å¼‚å¸¸ç»Ÿè®¡å’Œåˆ†æ
- **å¼‚å¸¸é¢‘ç‡ç»Ÿè®¡**: æŒ‰é”™è¯¯ç±»å‹å’Œæ¥å£ç»Ÿè®¡å¼‚å¸¸å‘ç”Ÿé¢‘ç‡
- **å¼‚å¸¸è¶‹åŠ¿åˆ†æ**: ç›‘æ§å¼‚å¸¸æ•°é‡å˜åŒ–è¶‹åŠ¿
- **å½±å“èŒƒå›´è¯„ä¼°**: åˆ†æå¼‚å¸¸å¯¹ç”¨æˆ·å’Œä¸šåŠ¡çš„å½±å“

#### 16.5.2 å…³é”®å¼‚å¸¸å‘Šè­¦
- **ç³»ç»Ÿçº§å¼‚å¸¸**: æ•°æ®åº“è¿æ¥å¤±è´¥ã€å­˜å‚¨æœåŠ¡å¼‚å¸¸
- **ä¸šåŠ¡çº§å¼‚å¸¸**: æ–‡æ¡£è§£æå¤±è´¥ç‡è¿‡é«˜ã€æ¨¡å‹è°ƒç”¨å¼‚å¸¸
- **å®‰å…¨å¼‚å¸¸**: è®¤è¯å¤±è´¥ã€æƒé™è¶Šç•Œå°è¯•

### 16.6 å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ

#### 16.6.1 å¼‚å¸¸æ•è·åŸåˆ™
1. **å°±è¿‘å¤„ç†**: åœ¨æœ€äº†è§£ä¸Šä¸‹æ–‡çš„åœ°æ–¹å¤„ç†å¼‚å¸¸
2. **åˆ†å±‚å¤„ç†**: ä¸åŒå±‚æ¬¡å¤„ç†ä¸åŒç±»å‹çš„å¼‚å¸¸
3. **è®°å½•å®Œæ•´**: è®°å½•å¼‚å¸¸çš„å®Œæ•´ä¸Šä¸‹æ–‡ä¿¡æ¯
4. **ç”¨æˆ·å‹å¥½**: å‘ç”¨æˆ·å±•ç¤ºæ˜“ç†è§£çš„é”™è¯¯ä¿¡æ¯

#### 16.6.2 å¼‚å¸¸å¤„ç†ç¦å¿Œ
- ç©ºcatchå—: æ•è·å¼‚å¸¸ä½†ä¸å¤„ç†
- è¿‡åº¦æ•è·: æ•è·æ‰€æœ‰å¼‚å¸¸è€Œä¸åŒºåˆ†ç±»å‹
- ä¿¡æ¯æ³„éœ²: å‘å‰ç«¯æš´éœ²æ•æ„Ÿçš„ç³»ç»Ÿä¿¡æ¯
- ä¸¢å¤±ä¸Šä¸‹æ–‡: é‡æ–°æŠ›å‡ºå¼‚å¸¸æ—¶ä¸¢å¤±åŸå§‹ä¿¡æ¯

## 17. æ—¥å¿—å¤„ç†æœºåˆ¶

### 17.1 æ—¥å¿—ç³»ç»Ÿæ¶æ„

#### 17.1.1 æ—¥å¿—åˆå§‹åŒ–æµç¨‹ (`api/utils/log_utils.py`)

RAGFlowä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—åˆå§‹åŒ–æœºåˆ¶ï¼Œæ”¯æŒå¤šè¿›ç¨‹å’Œæ–‡ä»¶è½®è½¬ï¼š

```python
def initRootLogger(logfile_basename: str, log_format: str = "%(asctime)-15s %(levelname)-8s %(process)d %(message)s"):
    global initialized_root_logger
    if initialized_root_logger:
        return
    initialized_root_logger = True

    logger = logging.getLogger()
    logger.handlers.clear()
    
    # æ—¥å¿—æ–‡ä»¶è·¯å¾„: logs/{logfile_basename}.log
    log_path = os.path.abspath(os.path.join(get_project_base_directory(), "logs", f"{logfile_basename}.log"))
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    formatter = logging.Formatter(log_format)

    # æ–‡ä»¶å¤„ç†å™¨ - 10MBè½®è½¬ï¼Œä¿ç•™5ä¸ªå¤‡ä»½
    handler1 = RotatingFileHandler(log_path, maxBytes=10*1024*1024, backupCount=5)
    handler1.setFormatter(formatter)
    logger.addHandler(handler1)

    # æ§åˆ¶å°å¤„ç†å™¨
    handler2 = logging.StreamHandler()
    handler2.setFormatter(formatter)
    logger.addHandler(handler2)
```

#### 17.1.2 å¤šè¿›ç¨‹æ—¥å¿—ç®¡ç†

**WebæœåŠ¡å™¨æ—¥å¿—** (`api/ragflow_server.py:23`):
```python
initRootLogger("ragflow_server")
# ç”Ÿæˆ: logs/ragflow_server.log
```

**ä»»åŠ¡æ‰§è¡Œå™¨æ—¥å¿—** (`rag/svr/task_executor.py:778`):
```python
CONSUMER_NAME = "task_executor_" + CONSUMER_NO  # å¦‚: task_executor_0
initRootLogger(CONSUMER_NAME)
# ç”Ÿæˆ: logs/task_executor_0.log, logs/task_executor_1.log ç­‰
```

### 17.2 æ—¥å¿—çº§åˆ«é…ç½®

#### 17.2.1 ç¯å¢ƒå˜é‡æ§åˆ¶ (`api/utils/log_utils.py:59-81`)

```python
# é€šè¿‡ç¯å¢ƒå˜é‡LOG_LEVELSæ§åˆ¶ä¸åŒåŒ…çš„æ—¥å¿—çº§åˆ«
# æ ¼å¼: LOG_LEVELS="peewee=DEBUG,pdfminer=WARNING,root=INFO"

LOG_LEVELS = os.environ.get("LOG_LEVELS", "")
pkg_levels = {}

# è§£ææ—¥å¿—çº§åˆ«é…ç½®
for pkg_name_level in LOG_LEVELS.split(","):
    terms = pkg_name_level.split("=")
    if len(terms) == 2:
        pkg_name, pkg_level = terms[0].strip(), terms[1].strip().upper()
        pkg_level = logging.getLevelName(pkg_level)
        if isinstance(pkg_level, int):
            pkg_levels[pkg_name] = logging.getLevelName(pkg_level)

# é»˜è®¤æ—¥å¿—çº§åˆ«è®¾ç½®
for pkg_name in ['peewee', 'pdfminer']:
    if pkg_name not in pkg_levels:
        pkg_levels[pkg_name] = logging.getLevelName(logging.WARNING)
if 'root' not in pkg_levels:
    pkg_levels['root'] = logging.getLevelName(logging.INFO)
```

#### 17.2.2 åŒ…çº§åˆ«æ—¥å¿—æ§åˆ¶

| åŒ…å | é»˜è®¤çº§åˆ« | è¯´æ˜ |
|------|----------|------|
| `root` | INFO | åº”ç”¨ä¸»æ—¥å¿— |
| `peewee` | WARNING | æ•°æ®åº“ORMæ—¥å¿— |
| `pdfminer` | WARNING | PDFè§£æåº“æ—¥å¿— |
| å…¶ä»–åŒ… | INFO | ç»§æ‰¿rootçº§åˆ« |

### 17.3 æ—¥å¿—è®°å½•æ¨¡å¼

#### 17.3.1 å¼‚å¸¸æ—¥å¿—è®°å½•

**å®Œæ•´å †æ ˆè®°å½•**:
```python
# è®°å½•å¼‚å¸¸çš„å®Œæ•´å †æ ˆä¿¡æ¯
logging.exception(e)

# è®°å½•è‡ªå®šä¹‰å¼‚å¸¸ä¿¡æ¯
logging.error(f"File upload failed: {filename}, error: {str(e)}")
```

**ç»“æ„åŒ–å¼‚å¸¸ä¿¡æ¯**:
```python
def log_exception(e, *args):
    logging.exception(e)      # è®°å½•å¼‚å¸¸å †æ ˆ
    for a in args:
        logging.error(str(a)) # è®°å½•é¢å¤–ä¸Šä¸‹æ–‡
    raise e
```

#### 17.3.2 ä¸šåŠ¡æ—¥å¿—è®°å½•

**æ“ä½œæ—¥å¿—**:
```python
logging.info(f"Document uploaded: {filename}, size: {file_size}, user: {user_id}")
logging.info(f"Task started: {task_id}, type: {task_type}")
```

**æ€§èƒ½æ—¥å¿—**:
```python
st = timer()
# ... ä¸šåŠ¡å¤„ç†
logging.info(f"Processing time: {timer() - st:.2f}s")
```

### 17.4 æ—¥å¿—åˆ†æ–‡ä»¶æ–¹æ¡ˆè®¾è®¡

#### 17.4.1 å½“å‰é—®é¢˜åˆ†æ
- **å•æ–‡ä»¶æ··åˆ**: æ‰€æœ‰çº§åˆ«æ—¥å¿—å†™å…¥åŒä¸€æ–‡ä»¶
- **æŸ¥æ‰¾å›°éš¾**: å¼‚å¸¸ä¿¡æ¯ä¸å¸¸è§„ä¿¡æ¯æ··åˆ
- **æ–‡ä»¶è¿‡å¤§**: å•ä¸ªæ—¥å¿—æ–‡ä»¶å®¹æ˜“è¿‡å¤§

#### 17.4.2 åˆ†æ–‡ä»¶æ–¹æ¡ˆè®¾è®¡

**ä¿®æ”¹`api/utils/log_utils.py`å®ç°æ—¥å¿—åˆ†æ–‡ä»¶**:

```python
def initRootLogger(logfile_basename: str, log_format: str = "%(asctime)-15s %(levelname)-8s %(process)d %(message)s"):
    global initialized_root_logger
    if initialized_root_logger:
        return
    initialized_root_logger = True

    logger = logging.getLogger()
    logger.handlers.clear()
    
    logs_dir = os.path.abspath(os.path.join(get_project_base_directory(), "logs"))
    os.makedirs(logs_dir, exist_ok=True)
    formatter = logging.Formatter(log_format)

    # 1. INFOåŠä»¥ä¸‹çº§åˆ«æ—¥å¿—æ–‡ä»¶ (info.log)
    info_log_path = os.path.join(logs_dir, f"{logfile_basename}_info.log")
    info_handler = RotatingFileHandler(info_log_path, maxBytes=10*1024*1024, backupCount=5)
    info_handler.setFormatter(formatter)
    info_handler.setLevel(logging.INFO)
    info_handler.addFilter(lambda record: record.levelno <= logging.INFO)
    logger.addHandler(info_handler)

    # 2. ERRORåŠä»¥ä¸Šçº§åˆ«æ—¥å¿—æ–‡ä»¶ (error.log) - åŒ…å«å®Œæ•´å †æ ˆ
    error_log_path = os.path.join(logs_dir, f"{logfile_basename}_error.log")
    error_handler = RotatingFileHandler(error_log_path, maxBytes=10*1024*1024, backupCount=5)
    error_handler.setFormatter(logging.Formatter(
        "%(asctime)-15s %(levelname)-8s %(process)d %(pathname)s:%(lineno)d %(funcName)s() %(message)s"
    ))
    error_handler.setLevel(logging.ERROR)
    logger.addHandler(error_handler)

    # 3. æ§åˆ¶å°è¾“å‡º (ä»…æ˜¾ç¤ºWARNINGåŠä»¥ä¸Š)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    console_handler.setLevel(logging.WARNING)
    logger.addHandler(console_handler)

    # 4. è®¾ç½®root loggerçº§åˆ«
    logger.setLevel(logging.INFO)
    
    logging.captureWarnings(True)
```

#### 17.4.3 åˆ†æ–‡ä»¶ç»“æœ

**æ—¥å¿—æ–‡ä»¶ç»“æ„**:
```
logs/
â”œâ”€â”€ ragflow_server_info.log      # WebæœåŠ¡å™¨å¸¸è§„æ—¥å¿—
â”œâ”€â”€ ragflow_server_error.log     # WebæœåŠ¡å™¨å¼‚å¸¸æ—¥å¿—  
â”œâ”€â”€ task_executor_0_info.log     # ä»»åŠ¡æ‰§è¡Œå™¨0å¸¸è§„æ—¥å¿—
â”œâ”€â”€ task_executor_0_error.log    # ä»»åŠ¡æ‰§è¡Œå™¨0å¼‚å¸¸æ—¥å¿—
â””â”€â”€ ...
```

**æ—¥å¿—å†…å®¹åˆ†ç¦»**:
- **info.log**: åŒ…å«INFOã€DEBUGçº§åˆ«çš„ä¸šåŠ¡æ—¥å¿—
- **error.log**: åŒ…å«ERRORã€CRITICALçº§åˆ«çš„å¼‚å¸¸æ—¥å¿—ï¼ŒåŒ…å«å®Œæ•´å †æ ˆä¿¡æ¯

### 17.5 å¼‚å¸¸æ—¥å¿—å¢å¼ºæ ¼å¼

#### 17.5.1 è¯¦ç»†å¼‚å¸¸æ ¼å¼

**error.logä¸“ç”¨æ ¼å¼**:
```python
# åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¼‚å¸¸æ—¥å¿—æ ¼å¼
error_format = "%(asctime)-15s %(levelname)-8s %(process)d %(pathname)s:%(lineno)d %(funcName)s() %(message)s"

# ç¤ºä¾‹è¾“å‡º:
# 2024-01-15 10:30:45 ERROR    1234 /app/api/apps/document_app.py:125 upload() File upload failed: document.pdf, ValueError: Invalid file type
```

#### 17.5.2 ç»“æ„åŒ–å¼‚å¸¸è®°å½•

**è‡ªå®šä¹‰å¼‚å¸¸è®°å½•å‡½æ•°**:
```python
def log_detailed_exception(e, context=None):
    """è®°å½•è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯ï¼ŒåŒ…å«ä¸Šä¸‹æ–‡"""
    import traceback
    
    exc_info = {
        "exception_type": type(e).__name__,
        "exception_message": str(e),
        "traceback": traceback.format_exc(),
        "context": context or {}
    }
    
    logging.error(f"Exception Details: {json.dumps(exc_info, indent=2)}")
```

### 17.6 å‰ç«¯å‹å¥½çš„é”™è¯¯å¤„ç†

#### 17.6.1 é”™è¯¯ä¿¡æ¯è„±æ•

**åˆ›å»ºç”¨æˆ·å‹å¥½çš„é”™è¯¯å¤„ç†å‡½æ•°**:
```python
def create_user_friendly_error(e, default_message="æ“ä½œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"):
    """åˆ›å»ºç”¨æˆ·å‹å¥½çš„é”™è¯¯å“åº”ï¼Œéšè—æŠ€æœ¯ç»†èŠ‚"""
    
    # 1. è®°å½•å®Œæ•´å¼‚å¸¸åˆ°error.log
    logging.exception(f"System error occurred: {e}")
    
    # 2. æ ¹æ®å¼‚å¸¸ç±»å‹è¿”å›å‹å¥½æ¶ˆæ¯
    error_messages = {
        "OperationalError": "æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
        "FileNotFoundError": "æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤", 
        "PermissionError": "æƒé™ä¸è¶³ï¼Œè¯·è”ç³»ç®¡ç†å‘˜",
        "ValidationError": "è¾“å…¥æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥åé‡è¯•",
        "TimeoutError": "æœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
    }
    
    exception_name = type(e).__name__
    user_message = error_messages.get(exception_name, default_message)
    
    # 3. è¿”å›è„±æ•åçš„é”™è¯¯ä¿¡æ¯
    return get_json_result(
        code=settings.RetCode.EXCEPTION_ERROR, 
        message=user_message
    )
```

### 17.7 æ—¥å¿—ç›‘æ§å’Œåˆ†æ

#### 17.7.1 æ—¥å¿—åˆ†æå·¥å…·

**æ¨èé›†æˆå·¥å…·**:
- **ELK Stack**: Elasticsearch + Logstash + Kibana
- **Grafana + Loki**: è½»é‡çº§æ—¥å¿—èšåˆæ–¹æ¡ˆ
- **Prometheus + AlertManager**: æŒ‡æ ‡ç›‘æ§å’Œå‘Šè­¦

#### 17.7.2 å…³é”®ç›‘æ§æŒ‡æ ‡

**é”™è¯¯ç‡ç›‘æ§**:
- æ¯åˆ†é’Ÿé”™è¯¯æ—¥å¿—æ•°é‡
- ä¸åŒé”™è¯¯ç±»å‹çš„å æ¯”
- é”™è¯¯å¢é•¿è¶‹åŠ¿

**æ€§èƒ½ç›‘æ§**:
- è¯·æ±‚å“åº”æ—¶é—´
- æ–‡æ¡£å¤„ç†è€—æ—¶
- æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½

### 17.8 æ—¥å¿—é…ç½®å»ºè®®

#### 17.8.1 ç”Ÿäº§ç¯å¢ƒé…ç½®

```bash
# ç¯å¢ƒå˜é‡é…ç½®
export LOG_LEVELS="root=INFO,peewee=WARNING,pdfminer=WARNING"

# æ—¥å¿—è½®è½¬è®¾ç½®
# å»ºè®®å•æ–‡ä»¶å¤§å°: 10MB
# ä¿ç•™å¤‡ä»½æ•°: 5ä¸ª
# æ€»æ—¥å¿—å¤§å°æ§åˆ¶: ~50MB per service
```

#### 17.8.2 å¼€å‘ç¯å¢ƒé…ç½®

```bash
# å¼€å‘ç¯å¢ƒæ›´è¯¦ç»†çš„æ—¥å¿—
export LOG_LEVELS="root=DEBUG,peewee=INFO,pdfminer=INFO"

# æ§åˆ¶å°è¾“å‡ºçº§åˆ«è°ƒæ•´
# å¯ä»¥åœ¨ä»£ç ä¸­åŠ¨æ€è°ƒæ•´console_handler.setLevel(logging.DEBUG)
```

RAGFlowçš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—ç³»ç»Ÿè®¾è®¡ä½“ç°äº†ä¼ä¸šçº§åº”ç”¨çš„å®Œæ•´æ€§å’Œå¯ç»´æŠ¤æ€§ï¼Œé€šè¿‡åˆ†å±‚å¤„ç†ã€ç»Ÿä¸€æ ¼å¼ã€åˆ†æ–‡ä»¶å­˜å‚¨ç­‰æœºåˆ¶ï¼Œä¸ºç³»ç»Ÿè¿ç»´å’Œé—®é¢˜æ’æŸ¥æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚

## 18. æ•°æ®åº“åˆå§‹åŒ–æœºåˆ¶

### 18.1 æ•°æ®åº“è‡ªåŠ¨åˆå§‹åŒ–æ¦‚è¿°

RAGFlowé‡‡ç”¨æ™ºèƒ½åŒ–çš„æ•°æ®åº“åˆå§‹åŒ–æœºåˆ¶ï¼Œå½“é¡¹ç›®å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åˆ›å»ºç¼ºå¤±çš„æ•°æ®åº“è¡¨ã€‚å¼€å‘è€…åªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šæ•°æ®åº“åç§°ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å®Œæˆä»¥ä¸‹æ“ä½œï¼š

1. **æ•°æ®åº“è¿æ¥å»ºç«‹**ï¼šæ ¹æ®é…ç½®æ–‡ä»¶è¿æ¥åˆ°æŒ‡å®šæ•°æ®åº“
2. **è¡¨ç»“æ„æ£€æµ‹**ï¼šæ£€æŸ¥æ‰€æœ‰å®šä¹‰çš„ORMæ¨¡å‹å¯¹åº”çš„è¡¨æ˜¯å¦å­˜åœ¨
3. **è‡ªåŠ¨å»ºè¡¨**ï¼šä¸ºä¸å­˜åœ¨çš„è¡¨è‡ªåŠ¨åˆ›å»ºå®Œæ•´çš„è¡¨ç»“æ„
4. **æ¶æ„è¿ç§»**ï¼šå¯¹å·²æœ‰è¡¨æ‰§è¡Œå¿…è¦çš„å­—æ®µæ·»åŠ å’Œä¿®æ”¹
5. **åˆå§‹æ•°æ®å¡«å……**ï¼šåˆ›å»ºç³»ç»Ÿå¿…éœ€çš„åŸºç¡€æ•°æ®

### 18.2 æ ¸å¿ƒåˆå§‹åŒ–å‡½æ•°

#### 18.2.1 ä¸»åˆå§‹åŒ–å‡½æ•° (`api/db/db_models.py:422-446`)

**å‡½æ•°å**: `init_database_tables(alter_fields=[])`

**æ ¸å¿ƒæœºåˆ¶**:
```python
@DB.connection_context()
def init_database_tables(alter_fields=[]):
    # 1. ä½¿ç”¨åå°„è·å–æ‰€æœ‰æ•°æ®åº“æ¨¡å‹ç±»
    members = inspect.getmembers(sys.modules[__name__], inspect.isclass)
    table_objs = []
    create_failed_list = []
    
    # 2. éå†æ‰€æœ‰ç»§æ‰¿DataBaseModelçš„ç±»
    for name, obj in members:
        if obj != DataBaseModel and issubclass(obj, DataBaseModel):
            table_objs.append(obj)
            
            # 3. æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if not obj.table_exists():
                logging.debug(f"start create table {obj.__name__}")
                try:
                    # 4. è‡ªåŠ¨åˆ›å»ºè¡¨
                    obj.create_table()
                    logging.debug(f"create table success: {obj.__name__}")
                except Exception as e:
                    logging.exception(e)
                    create_failed_list.append(obj.__name__)
            else:
                logging.debug(f"table {obj.__name__} already exists, skip creation.")
    
    # 5. æ£€æŸ¥åˆ›å»ºç»“æœ
    if create_failed_list:
        logging.error(f"create tables failed: {create_failed_list}")
        raise Exception(f"create tables failed: {create_failed_list}")
    
    # 6. æ‰§è¡Œæ•°æ®åº“è¿ç§»
    migrate_db()
```

**å·¥ä½œåŸç†**:

1. **åå°„æœºåˆ¶**ï¼šä½¿ç”¨`inspect.getmembers()`åŠ¨æ€å‘ç°æ‰€æœ‰æ•°æ®åº“æ¨¡å‹ç±»
2. **ç»§æ‰¿æ£€æŸ¥**ï¼šç­›é€‰å‡ºç»§æ‰¿è‡ª`DataBaseModel`çš„ä¸šåŠ¡æ¨¡å‹ç±»
3. **å­˜åœ¨æ€§æ£€æµ‹**ï¼šè°ƒç”¨Peewee ORMçš„`table_exists()`æ–¹æ³•æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
4. **è‡ªåŠ¨åˆ›å»º**ï¼šä½¿ç”¨`create_table()`æ–¹æ³•åˆ›å»ºç¼ºå¤±çš„è¡¨
5. **é”™è¯¯å¤„ç†**ï¼šæ”¶é›†åˆ›å»ºå¤±è´¥çš„è¡¨åï¼Œç»Ÿä¸€æŠ¥å‘Šé”™è¯¯
6. **åç»­è¿ç§»**ï¼šè¡¨åˆ›å»ºå®Œæˆåæ‰§è¡Œæ¶æ„è¿ç§»

#### 18.2.2 æ•°æ®åº“é…ç½®åŠ è½½ (`api/settings.py:49-50`)

**é…ç½®åŠ è½½æµç¨‹**:
```python
DATABASE_TYPE = os.getenv("DB_TYPE", "mysql")  # é»˜è®¤MySQL
DATABASE = decrypt_database_config(name=DATABASE_TYPE)
```

**é…ç½®æ–‡ä»¶ä½ç½®**: `conf/service_conf.yaml`
```yaml
mysql:
  host: '172.20.208.1'
  port: 3306
  user: 'root'
  password: 'infiniflow'
  name: 'rag_flow'
  pool_recycle: 7200
  pool_size: 100
  max_overflow: 120
```

**é…ç½®è§£å¯†å‡½æ•°** (`api/utils/__init__.py:304-310`):
```python
def decrypt_database_config(database=None, passwd_key="password", name="database"):
    """
    ä»é…ç½®æ–‡ä»¶åŠ è½½æ•°æ®åº“é…ç½®ï¼Œæ”¯æŒå¯†ç è§£å¯†
    """
    database = get_base_config(name, {})
    if settings.ENCRYPT_KEY and passwd_key in database:
        # å¦‚æœå¯ç”¨åŠ å¯†ï¼Œè§£å¯†æ•°æ®åº“å¯†ç 
        database[passwd_key] = decrypt(database[passwd_key])
    return database
```

#### 18.2.3 æ•°æ®åº“è¿æ¥å»ºç«‹ (`api/db/db_models.py:238-263`)

**å•ä¾‹æ•°æ®åº“ç±»**:
```python
@singleton
class BaseDataBase:
    def __init__(self):
        database_config = settings.DATABASE.copy()
        db_name = database_config.pop("name")
        
        # æ ¹æ®æ•°æ®åº“ç±»å‹åˆ›å»ºè¿æ¥æ± 
        if settings.DATABASE_TYPE.lower() == "mysql":
            self.database_connection = PooledMySQLDatabase(
                db_name, **database_config
            )
        elif settings.DATABASE_TYPE.lower() in ["postgresql", "postgres"]:
            self.database_connection = PooledPostgresqlDatabase(
                db_name, **database_config
            )
        else:
            raise ValueError(f"Unsupported database type: {settings.DATABASE_TYPE}")
```

**è¿æ¥æ± é…ç½®**:
- **MySQL**: ä½¿ç”¨`PooledMySQLDatabase`
- **PostgreSQL**: ä½¿ç”¨`PooledPostgresqlDatabase`
- **è¿æ¥æ± å¤§å°**: é€šè¿‡é…ç½®æ–‡ä»¶çš„`pool_size`å’Œ`max_overflow`æ§åˆ¶
- **è¿æ¥å›æ”¶**: `pool_recycle`å‚æ•°æ§åˆ¶è¿æ¥å›æ”¶æ—¶é—´

### 18.3 æ•°æ®åº“è¿ç§»æœºåˆ¶

#### 18.3.1 è¿ç§»å‡½æ•° (`api/db/db_models.py:846-937`)

**è¿ç§»æ‰§è¡Œæµç¨‹**:
```python
def migrate_db():
    # æ ¹æ®æ•°æ®åº“ç±»å‹åˆ›å»ºè¿ç§»å™¨
    migrator = DatabaseMigrator[settings.DATABASE_TYPE.upper()].value(DB)
    
    # å®‰å…¨åœ°æ·»åŠ æ–°å­—æ®µ - ä½¿ç”¨try/excepté¿å…é‡å¤æ·»åŠ 
    try:
        migrate(migrator.add_column("file", "source_type", 
               CharField(max_length=128, null=False, default="", 
                        help_text="where dose this document come from", index=True)))
    except Exception:
        pass  # å­—æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡
        
    try:
        migrate(migrator.add_column("tenant", "rerank_id", 
               CharField(max_length=128, null=False, default="BAAI/bge-reranker-v2-m3", 
                        help_text="default rerank model ID")))
    except Exception:
        pass
        
    # ... æ›´å¤šè¿ç§»æ“ä½œ
```

**è¿ç§»ç±»å‹æ”¯æŒ**:
1. **æ·»åŠ å­—æ®µ**: `migrator.add_column()`
2. **ä¿®æ”¹å­—æ®µç±»å‹**: `migrator.alter_column_type()`
3. **ç´¢å¼•ç®¡ç†**: é€šè¿‡å­—æ®µå®šä¹‰çš„`index=True`è‡ªåŠ¨åˆ›å»º
4. **é»˜è®¤å€¼è®¾ç½®**: ä¸ºæ–°å¢å­—æ®µæä¾›åˆç†é»˜è®¤å€¼

#### 18.3.2 è¿ç§»å™¨å·¥å‚æ¨¡å¼

```python
class DatabaseMigrator(Enum):
    MYSQL = MySQLMigrator
    POSTGRES = PostgresqlMigrator
```

### 18.4 æ•°æ®æ¨¡å‹åŸºç±»

#### 18.4.1 DataBaseModelåŸºç±» (`api/db/db_models.py:417-420`)

```python
class DataBaseModel(BaseModel):
    class Meta:
        database = DB  # ç»‘å®šåˆ°å…¨å±€æ•°æ®åº“è¿æ¥
```

**åŸºç±»ç‰¹æ€§**:
- **ç»Ÿä¸€è¿æ¥**: æ‰€æœ‰æ¨¡å‹ç±»éƒ½ä½¿ç”¨ç›¸åŒçš„æ•°æ®åº“è¿æ¥
- **è‡ªåŠ¨å‘ç°**: é€šè¿‡ç»§æ‰¿å…³ç³»è¢«åˆå§‹åŒ–å‡½æ•°è‡ªåŠ¨å‘ç°
- **ORMåŠŸèƒ½**: ç»§æ‰¿Peeweeçš„å®Œæ•´ORMåŠŸèƒ½

#### 18.4.2 æ ¸å¿ƒæ•°æ®æ¨¡å‹ç¤ºä¾‹

**ç”¨æˆ·æ¨¡å‹** (`Tenant`, `User`, `UserTenant`):
```python
class Tenant(DataBaseModel):
    id = CharField(max_length=32, primary_key=True)
    name = CharField(max_length=255, null=False)
    llm_id = CharField(max_length=255, default="")
    embd_id = CharField(max_length=255, default="")
    # ... å…¶ä»–å­—æ®µ
```

**çŸ¥è¯†åº“æ¨¡å‹** (`Knowledgebase`, `Document`, `Chunk`):
```python
class Knowledgebase(DataBaseModel):
    id = CharField(max_length=32, primary_key=True)
    tenant_id = CharField(max_length=32, null=False)
    name = CharField(max_length=128, null=False)
    # ... å…¶ä»–å­—æ®µ
```

### 18.5 ç³»ç»Ÿå¯åŠ¨åºåˆ—

#### 18.5.1 WebæœåŠ¡å™¨å¯åŠ¨ (`api/ragflow_server.py:97-99`)

```python
# æ•°æ®åº“åˆå§‹åŒ–
init_web_db()     # åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„
init_web_data()   # å¡«å……åˆå§‹æ•°æ®
```

**å¯åŠ¨é¡ºåº**:
1. **é…ç½®åŠ è½½**: ä»`conf/service_conf.yaml`è¯»å–æ•°æ®åº“é…ç½®
2. **è¿æ¥å»ºç«‹**: åˆ›å»ºæ•°æ®åº“è¿æ¥æ± 
3. **è¡¨ç»“æ„åˆå§‹åŒ–**: è°ƒç”¨`init_database_tables()`
4. **æ•°æ®è¿ç§»**: æ‰§è¡Œæ¶æ„æ›´æ–°
5. **åˆå§‹æ•°æ®**: åˆ›å»ºé»˜è®¤çš„LLMå‚å•†ã€æ¨¡æ¿ç­‰æ•°æ®

#### 18.5.2 åˆå§‹æ•°æ®å¡«å…… (`api/db/init_data.py:168-177`)

```python
def init_web_data():
    """åˆå§‹åŒ–Webåº”ç”¨çš„åŸºç¡€æ•°æ®"""
    init_llm_factory()      # åˆå§‹åŒ–LLMä¾›åº”å•†ä¿¡æ¯ã€‚llmä¾›åº”å•†çš„åŸç”Ÿæ•°æ®æ¥è‡ªconf/llm_factories.json
    add_graph_templates()  # åˆå§‹åŒ–å›¾è°±æ¨¡æ¿,æ¥è‡ª/agent/templates/ä¸‹çš„json
    # å…¶ä»–åˆå§‹åŒ–æ“ä½œ...
```

### 18.6 é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

#### 18.6.1 å»ºè¡¨å¤±è´¥å¤„ç†

```python
if create_failed_list:
    logging.error(f"create tables failed: {create_failed_list}")
    raise Exception(f"create tables failed: {create_failed_list}")
```

**å¤±è´¥æ¢å¤ç­–ç•¥**:
1. **è¯¦ç»†æ—¥å¿—**: è®°å½•å¤±è´¥çš„è¡¨åå’ŒåŸå› 
2. **å…¨å±€å¼‚å¸¸**: å»ºè¡¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸ï¼Œé˜»æ­¢ç³»ç»Ÿå¯åŠ¨
3. **æ‰‹åŠ¨å¹²é¢„**: ç®¡ç†å‘˜å¯æ ¹æ®æ—¥å¿—ä¿¡æ¯æ‰‹åŠ¨ä¿®å¤

#### 18.6.2 è¿æ¥å¼‚å¸¸å¤„ç†

**è¿æ¥æ± ç®¡ç†**:
```python
def close_connection():
    try:
        if DB:
            DB.close_stale(age=30)  # å…³é—­30ç§’ä»¥ä¸Šçš„é™ˆæ—§è¿æ¥
    except Exception as e:
        logging.exception(e)
```

**é‡è¯•æœºåˆ¶**:
- æ•°æ®åº“æ“ä½œæ”¯æŒé‡è¯•è£…é¥°å™¨`@with_retry`
- è¿æ¥å¤±è´¥æ—¶è‡ªåŠ¨é‡è¿
- åˆ†å¸ƒå¼é”ç¡®ä¿å¤šå®ä¾‹å®‰å…¨

### 18.7 æ”¯æŒçš„æ•°æ®åº“ç±»å‹

#### 18.7.1 MySQLæ”¯æŒ

**é…ç½®ç¤ºä¾‹**:

```yaml
mysql:
  host: 'localhost'
  port: 3306
  user: 'ragflow'
  password: 'your_password'
  name: 'ragflow_db'
  charset: 'utf8mb4'
  pool_size: 100
  max_overflow: 120
  pool_recycle: 7200
```

**ç‰¹æ€§æ”¯æŒ**:
- è¿æ¥æ± ç®¡ç†
- äº‹åŠ¡æ”¯æŒ
- åˆ†å¸ƒå¼é”(`GET_LOCK`/`RELEASE_LOCK`)
- å­—ç¬¦é›†ï¼šé»˜è®¤utf8mb4

#### 18.7.2 PostgreSQLæ”¯æŒ

**é…ç½®ç¤ºä¾‹**:
```yaml
postgres:
  host: 'localhost'
  port: 5432
  user: 'ragflow'
  password: 'your_password'
  name: 'ragflow_db'
  pool_size: 100
  max_overflow: 120
  pool_recycle: 7200
```

**ç‰¹æ€§æ”¯æŒ**:
- è¿æ¥æ± ç®¡ç†
- äº‹åŠ¡æ”¯æŒ
- Advisoryé”(`pg_try_advisory_lock`)
- JSONå­—æ®µåŸç”Ÿæ”¯æŒ

### 18.8 é…ç½®è¦æ±‚å’Œæœ€ä½³å®è·µ

#### 18.8.1 æœ€ä½é…ç½®è¦æ±‚

**æ•°æ®åº“é…ç½®**:
- æ•°æ®åº“åç§°ï¼šå¯è‡ªå®šä¹‰ï¼Œç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºè¡¨
- ç”¨æˆ·æƒé™ï¼šéœ€è¦CREATEã€ALTERã€INSERTã€SELECTã€UPDATEã€DELETEæƒé™
- å­—ç¬¦ç¼–ç ï¼šæ¨èUTF-8/UTF8MB4
- å¼•æ“ç±»å‹ï¼šMySQLæ¨èInnoDB

#### 18.8.2 ç”Ÿäº§ç¯å¢ƒå»ºè®®

**è¿æ¥æ± é…ç½®**:
```yaml
mysql:
  pool_size: 100          # åŸºç¡€è¿æ¥æ± å¤§å°
  max_overflow: 120       # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
  pool_recycle: 7200      # è¿æ¥å›æ”¶æ—¶é—´(2å°æ—¶)
  pool_timeout: 30        # è·å–è¿æ¥è¶…æ—¶æ—¶é—´
  pool_pre_ping: true     # è¿æ¥å‰pingæ£€æŸ¥
```

**æ€§èƒ½ä¼˜åŒ–**:
- åˆç†è®¾ç½®è¿æ¥æ± å¤§å°ï¼Œé¿å…è¿æ¥è€—å°½
- å®šæœŸå›æ”¶é™ˆæ—§è¿æ¥ï¼Œé˜²æ­¢è¿æ¥æ³„éœ²
- ä½¿ç”¨åˆ†å¸ƒå¼é”é¿å…å¹¶å‘å»ºè¡¨å†²çª
- ç›‘æ§æ•°æ®åº“è¿æ¥çŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡

#### 18.8.3 æ•…éšœæ’æŸ¥

**å¸¸è§é—®é¢˜**:
1. **è¿æ¥å¤±è´¥**: æ£€æŸ¥æ•°æ®åº“æœåŠ¡çŠ¶æ€å’Œç½‘ç»œè¿é€šæ€§
2. **æƒé™ä¸è¶³**: ç¡®ä¿æ•°æ®åº“ç”¨æˆ·å…·æœ‰å»ºè¡¨æƒé™
3. **å­—ç¬¦ç¼–ç **: ç¡®ä¿æ•°æ®åº“å’Œè¡¨ä½¿ç”¨UTF-8ç¼–ç 
4. **è¡¨å·²å­˜åœ¨**: ç³»ç»Ÿä¼šè‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„è¡¨

**è°ƒè¯•æ–¹æ³•**:
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export LOG_LEVELS="root=DEBUG,peewee=DEBUG"

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
python -c "from api.db.db_models import DB; print(DB.connect())"

# æ‰‹åŠ¨æ‰§è¡Œåˆå§‹åŒ–
python -c "from api.db.db_models import init_database_tables; init_database_tables()"
```

### 18.9 æ‰©å±•å’Œå®šåˆ¶

#### 18.9.1 æ·»åŠ æ–°è¡¨

**åˆ›å»ºæ–°æ¨¡å‹**:
```python
class NewModel(DataBaseModel):
    id = CharField(max_length=32, primary_key=True)
    name = CharField(max_length=255, null=False)
    created_at = DateTimeField(auto_now_add=True)
    
    class Meta:
        table_name = 'new_model'
```

**è‡ªåŠ¨å»ºè¡¨**ï¼šæ–°æ¨¡å‹ä¼šåœ¨ä¸‹æ¬¡å¯åŠ¨æ—¶è‡ªåŠ¨åˆ›å»ºå¯¹åº”è¡¨

#### 18.9.2 æ·»åŠ å­—æ®µè¿ç§»

**åœ¨migrate_db()ä¸­æ·»åŠ **:
```python
try:
    migrate(migrator.add_column("new_model", "new_field", 
           CharField(max_length=100, null=True, default="")))
except Exception:
    pass
```

#### 18.9.3 è‡ªå®šä¹‰åˆå§‹åŒ–æ•°æ®

**æ‰©å±•init_web_data()**:
```python
def init_custom_data():
    """åˆå§‹åŒ–è‡ªå®šä¹‰æ•°æ®"""
    # åˆ›å»ºé»˜è®¤é…ç½®ã€ç”¨æˆ·ç­‰
    pass
```

RAGFlowçš„æ•°æ®åº“åˆå§‹åŒ–æœºåˆ¶è®¾è®¡ç®€æ´è€Œå¼ºå¤§ï¼Œå¼€å‘è€…åªéœ€æä¾›æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼Œç³»ç»Ÿå³å¯è‡ªåŠ¨å®Œæˆæ‰€æœ‰è¡¨ç»“æ„çš„åˆ›å»ºå’Œç»´æŠ¤ã€‚è¿™ç§è®¾è®¡å¤§å¤§ç®€åŒ–äº†éƒ¨ç½²æµç¨‹ï¼ŒåŒæ—¶ç¡®ä¿äº†æ•°æ®åº“æ¶æ„çš„ä¸€è‡´æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚


# RAGFlowæ–‡æ¡£åˆ‡ç‰‡æ–¹æ³•ä¸“é¢˜çŸ¥è¯†

## 1. åˆ‡ç‰‡ç³»ç»Ÿæ¶æ„æ¦‚è¿°

RAGFlowé‡‡ç”¨ä¸‰å±‚æ–‡æ¡£å¤„ç†æ¶æ„ï¼š
1. **åŸºç¡€è§£æå±‚**ï¼šå„ç§æ–‡æ¡£æ ¼å¼çš„åŸºç¡€åˆ‡ç‰‡å¤„ç†ï¼ˆnaiveã€qaã€paperã€bookç­‰ï¼‰
2. **å†…å®¹å¢å¼ºå±‚**ï¼šRAPTORé€’å½’èšç±»å’ŒTAGæ ‡ç­¾å¢å¼º
3. **åå¤„ç†å±‚**ï¼šå‘é‡åŒ–ã€ç´¢å¼•æ„å»ºã€çŸ¥è¯†å›¾è°±æ„å»ºç­‰

### æ ¸å¿ƒç»„ä»¶å…³ç³»
- **Factoryæ¨¡å¼**ï¼š`rag/svr/task_executor.py`ä¸­çš„FACTORYå­—å…¸ç®¡ç†æ‰€æœ‰è§£æå™¨
- **æšä¸¾å®šä¹‰**ï¼š`api/db/__init__.py`ä¸­çš„ParserTypeæšä¸¾å®šä¹‰æ‰€æœ‰åˆ‡ç‰‡ç±»å‹
- **é…ç½®ç®¡ç†**ï¼š`api/settings.py`ä¸­çš„PARSERSé…ç½®å‰ç«¯æ˜¾ç¤ºåç§°
- **å‰ç«¯é…ç½®**ï¼š`web/src/constants/knowledge.ts`ä¸­çš„DocumentParserTypeæšä¸¾

## 2. ç°æœ‰åˆ‡ç‰‡æ–¹æ³•è¯¦è§£

### åŸºç¡€åˆ‡ç‰‡æ–¹æ³•
- **Generalï¼ˆnaiveï¼‰**ï¼šé€šç”¨åˆ‡ç‰‡ï¼Œæ”¯æŒPDFã€DOCXã€Markdownç­‰å¤šæ ¼å¼
- **Q&Aï¼ˆqaï¼‰**ï¼šé—®ç­”å¯¹åˆ‡ç‰‡ï¼Œæ”¯æŒExcelã€CSVã€PDFã€Markdownã€DOCXæ ¼å¼
- **Resumeï¼ˆresumeï¼‰**ï¼šç®€å†ä¸“ç”¨åˆ‡ç‰‡
- **Manualï¼ˆmanualï¼‰**ï¼šæ‰‹å†Œæ–‡æ¡£åˆ‡ç‰‡
- **Tableï¼ˆtableï¼‰**ï¼šè¡¨æ ¼ä¸“ç”¨åˆ‡ç‰‡
- **Paperï¼ˆpaperï¼‰**ï¼šå­¦æœ¯è®ºæ–‡åˆ‡ç‰‡
- **Bookï¼ˆbookï¼‰**ï¼šä¹¦ç±ç« èŠ‚åˆ‡ç‰‡
- **Lawsï¼ˆlawsï¼‰**ï¼šæ³•å¾‹æ–‡æ¡£åˆ‡ç‰‡
- **Presentationï¼ˆpresentationï¼‰**ï¼šæ¼”ç¤ºæ–‡ç¨¿åˆ‡ç‰‡
- **Pictureï¼ˆpictureï¼‰**ï¼šå›¾ç‰‡æ–‡æ¡£åˆ‡ç‰‡
- **Oneï¼ˆoneï¼‰**ï¼šå•æ–‡æ¡£æ•´ä½“åˆ‡ç‰‡
- **Audioï¼ˆaudioï¼‰**ï¼šéŸ³é¢‘æ–‡æ¡£åˆ‡ç‰‡
- **Emailï¼ˆemailï¼‰**ï¼šé‚®ä»¶æ–‡æ¡£åˆ‡ç‰‡
- **TAGï¼ˆtagï¼‰**ï¼šæ ‡ç­¾åŒ–åˆ‡ç‰‡ï¼Œæ”¯æŒExcelã€CSVã€TXTæ ¼å¼

### ç‰¹æ®Šå¤„ç†æ–¹æ³•
- **Knowledge Graphï¼ˆknowledge_graphï¼‰**ï¼šä½¿ç”¨naiveåŸºç¡€è§£æï¼Œä½†å¯ç”¨GraphRAGçŸ¥è¯†å›¾è°±æ„å»º
- **MdChapterï¼ˆmdchapterï¼‰**ï¼šæ–°å¢çš„Markdownç« èŠ‚ä¸“ç”¨åˆ‡ç‰‡æ–¹æ³•

## 3. RAPTORå’ŒTAGå¢å¼ºæœºåˆ¶

### RAPTORï¼ˆRecursive Abstractive Processing for Tree-Organized Retrievalï¼‰
- **åŠŸèƒ½**ï¼šé€’å½’æŠ½è±¡å¤„ç†ï¼Œæ„å»ºæ ‘çŠ¶ç»„ç»‡çš„æ£€ç´¢ç»“æ„
- **å®ç°ä½ç½®**ï¼š`rag/raptor.py`
- **é…ç½®å‚æ•°**ï¼š
  - `use_raptor`: æ˜¯å¦å¯ç”¨RAPTOR
  - `max_token`: æœ€å¤§tokenæ•°é‡ï¼ˆé»˜è®¤256ï¼‰
  - `threshold`: èšç±»é˜ˆå€¼ï¼ˆé»˜è®¤0.1ï¼‰
  - `max_cluster`: æœ€å¤§èšç±»æ•°é‡ï¼ˆé»˜è®¤64ï¼‰
  - `random_seed`: éšæœºç§å­ï¼ˆé»˜è®¤0ï¼‰

### TAGæ ‡ç­¾å¢å¼º
- **åŠŸèƒ½**ï¼šä¸ºæ–‡æ¡£å—æ·»åŠ æ™ºèƒ½æ ‡ç­¾
- **å®ç°ä½ç½®**ï¼š`rag/app/tag.py`
- **æ”¯æŒæ–¹æ³•**ï¼šä¸å¤§éƒ¨åˆ†åŸºç¡€è§£æå™¨å…¼å®¹

### å…¼å®¹æ€§çŸ©é˜µ
 < /dev/null |  åŸºç¡€è§£æå™¨ | RAPTORæ”¯æŒ | TAGæ”¯æŒ |
|------------|------------|---------|
| General    | âœ“          | âœ“       |
| Q&A        | âœ“          | âœ“       |
| Paper      | âœ“          | âœ“       |
| Book       | âœ“          | âœ“       |
| Manual     | âœ“          | âœ“       |
| Laws       | âœ“          | âœ“       |
| MdChapter  | âœ“          | âœ“       |
| Table      | âœ—          | âœ—       |
| Picture    | âœ—          | âœ—       |
| Audio      | âœ—          | âœ—       |
| Email      | âœ—          | âœ—       |

## 4. å‰ç«¯é…ç½®ç³»ç»Ÿ

### æ–‡ä»¶æ‰©å±•åä¸è§£æå™¨æ˜ å°„
ä½ç½®ï¼š`web/src/components/chunk-method-dialog/hooks.ts`
```typescript
const ParserListMap = new Map([
  [['pdf'], ['naive', 'resume', 'manual', 'paper', 'book', 'laws', 'presentation', 'one', 'qa', 'knowledge_graph']],
  [['doc', 'docx'], ['naive', 'resume', 'book', 'laws', 'one', 'qa', 'manual', 'knowledge_graph']],
  [['md'], ['naive', 'qa', 'knowledge_graph', 'mdchapter']],
  // ... å…¶ä»–æ˜ å°„
]);
```

### é…ç½®ç»„ä»¶æ˜ å°„
ä½ç½®ï¼š`web/src/pages/dataset/setting/chunk-method-form.tsx`
```typescript
const ConfigurationComponentMap = {
  [DocumentParserType.Naive]: NaiveConfiguration,
  [DocumentParserType.MdChapter]: MdChapterConfiguration,
  // ... å…¶ä»–æ˜ å°„
};
```

## 5. å—ç®¡ç†APIç³»ç»Ÿ

### æ ¸å¿ƒæ¥å£
ä½ç½®ï¼š`api/apps/chunk_app.py`
- **GET /list**ï¼šè·å–æ–‡æ¡£å—åˆ—è¡¨
- **GET /get/:chunk_id**ï¼šè·å–ç‰¹å®šå—è¯¦æƒ…
- **POST /set**ï¼šæ›´æ–°å—å†…å®¹
- **POST /create**ï¼šåˆ›å»ºæ–°å—
- **DELETE /rm**ï¼šåˆ é™¤å—
- **POST /switch**ï¼šåˆ‡æ¢å—çŠ¶æ€
- **POST /retrieval_test**ï¼šæ£€ç´¢æµ‹è¯•

### å‘é‡ç”Ÿæˆé€»è¾‘
```python
# æ–‡æ¡£åç§°æƒé‡0.1 + å†…å®¹æƒé‡0.9
v = 0.1 * v[0] + 0.9 * v[1]
```

## 6. æ ¸å¿ƒåˆå¹¶ç®—æ³•

### ä¸»è¦ç®—æ³•ä½ç½®ï¼š`rag/nlp/`
- **naive_merge**ï¼šé€šç”¨åˆå¹¶ç®—æ³•
- **naive_merge_with_images**ï¼šæ”¯æŒå›¾ç‰‡çš„åˆå¹¶ç®—æ³•
- **naive_merge_docx**ï¼šDOCXä¸“ç”¨åˆå¹¶ç®—æ³•
- **hierarchical_merge**ï¼šåˆ†å±‚åˆå¹¶ç®—æ³•

### RAPTORèšç±»ç®—æ³•
- **å®ç°**ï¼š`rag/raptor.py`ä¸­çš„RecursiveAbstractiveProcessing4TreeOrganizedRetrievalç±»
- **åŠŸèƒ½**ï¼šé€’å½’èšç±»ï¼Œæ„å»ºå¤šå±‚æ¬¡æ–‡æ¡£ç»“æ„

## 7. GraphRAGçŸ¥è¯†å›¾è°±

### æ ¸å¿ƒåŠŸèƒ½
- **å®ä½“æå–**ï¼šä»æ–‡æ¡£ä¸­æå–äººç‰©ã€åœ°ç‚¹ã€ç»„ç»‡ç­‰å®ä½“
- **å…³ç³»æ„å»º**ï¼šåˆ†æå®ä½“é—´çš„å…³ç³»
- **å›¾è°±æŸ¥è¯¢**ï¼šæ”¯æŒå›¾è°±ç»“æ„çš„æ£€ç´¢

### é…ç½®å‚æ•°
- `use_graphrag`: æ˜¯å¦å¯ç”¨GraphRAG
- `entity_types`: å®ä½“ç±»å‹åˆ—è¡¨ï¼ˆé»˜è®¤ï¼šorganization, person, geo, event, categoryï¼‰
- `method`: æ„å»ºæ–¹æ³•ï¼ˆgeneral/lightï¼‰

## 8. æ–°å¢MdChapteråˆ‡ç‰‡æ–¹æ³•å®ç°

### åç«¯å®ç°
1. **è§£æå™¨æ–‡ä»¶**ï¼š`rag/app/mdchapter.py`ï¼ˆå¤åˆ¶è‡ªnaive.pyï¼‰
2. **æšä¸¾æ³¨å†Œ**ï¼š`api/db/__init__.py`æ·»åŠ `MDCHAPTER = "mdchapter"`
3. **å·¥å‚æ³¨å†Œ**ï¼š`rag/svr/task_executor.py`çš„FACTORYå­—å…¸æ·»åŠ mdchapteræ˜ å°„
4. **é…ç½®æ³¨å†Œ**ï¼š`api/settings.py`çš„PARSERSæ·»åŠ "mdchapter:MdChapter"

### å‰ç«¯å®ç°
1. **ç±»å‹å®šä¹‰**ï¼š`web/src/constants/knowledge.ts`æ·»åŠ `MdChapter = 'mdchapter'`
2. **æ–‡ä»¶æ˜ å°„**ï¼š`web/src/components/chunk-method-dialog/hooks.ts`çš„mdæ–‡ä»¶æ”¯æŒæ·»åŠ mdchapter
3. **é…ç½®ç»„ä»¶**ï¼š`web/src/pages/dataset/setting/configuration/mdchapter.tsx`
4. **ç»„ä»¶æ˜ å°„**ï¼š`web/src/pages/dataset/setting/chunk-method-form.tsx`æ·»åŠ MdChapterConfigurationæ˜ å°„
5. **å›¾ç‰‡æ˜ å°„**ï¼š`web/src/pages/dataset/setting/utils.ts`æ·»åŠ mdchapterå›¾ç‰‡æ˜ å°„

### ç‰¹æ€§æ”¯æŒ
- å®Œå…¨å…¼å®¹RAPTORé€’å½’èšç±»
- å®Œå…¨å…¼å®¹TAGæ ‡ç­¾å¢å¼º
- æ”¯æŒmdchapter + RAPTOR + TAGç»„åˆé…ç½®
- ä¸“é—¨é’ˆå¯¹Markdownæ–‡æ¡£çš„ç« èŠ‚åˆ‡åˆ†ä¼˜åŒ–

